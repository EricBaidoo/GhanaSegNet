{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c8dc2b6",
   "metadata": {},
   "source": [
    "# Colab: Evaluate Checkpoints & Package Results\n",
    "\n",
    "This notebook mounts Google Drive, copies checkpoints/results into the Colab runtime, installs dependencies, runs either a quick \"Path A\" analysis (process existing JSONs) or a full \"Path B\" evaluation (run `analysis/evaluate_checkpoints_per_class.py` on checkpoints), generates plots and per-class JSON outputs, and packages the small outputs back to Drive.\n",
    "\n",
    "How to use:\n",
    "1. Open this notebook in Colab (File > Upload notebook or via `colab.research.google.com` and select this GitHub/Drive file).\n",
    "2. Run cells sequentially. Use Path A if you already have `results/*.json` in Drive. Use Path B to evaluate checkpoints in Drive (requires GPU and the dataset or access to dataset files).\n",
    "\n",
    "This notebook will write a zip file to `/content/drive/My Drive/GhanaSegNet_Results/results_per_class_summary_jsons.zip` containing the small JSON and PNG outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8a1a83",
   "metadata": {},
   "source": [
    "## 1) Check for an existing Colab notebook\n",
    "\n",
    "This section searches the repository for other notebooks. It can help avoid duplicates and detect if a Colab-ready notebook already exists.\n",
    "\n",
    "Run the Python cell below to list any `.ipynb` files in the repo and preview the first few lines of any candidate notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553ab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Search for notebooks in repo\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "repo_root = Path('/content/GhanaSegNet') if Path('/content/GhanaSegNet').exists() else Path('.')\n",
    "notebooks = [str(p) for p in Path('.').rglob('*.ipynb')]\n",
    "print(f'Found {len(notebooks)} notebook(s) in repo root:')\n",
    "for nb in notebooks:\n",
    "    print('-', nb)\n",
    "\n",
    "# Preview the first candidate (if any)\n",
    "if notebooks:\n",
    "    with open(notebooks[0], 'r', encoding='utf-8') as f:\n",
    "        first_lines = ''.join([next(f) for _ in range(5)])\n",
    "    print('\\nPreview of', notebooks[0], ':')\n",
    "    print(first_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d989274",
   "metadata": {},
   "source": [
    "## 2) Prepare Colab-compatible notebook metadata\n",
    "\n",
    "If you'd like to programmatically patch notebook metadata to be Colab-friendly (kernelspec and runtime), run the helper below. It uses nbformat to open and rewrite metadata.\n",
    "\n",
    "Note: This step is optional; Colab generally handles metadata itself when opening a notebook from Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a5ba05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: helper to update notebook metadata to be Colab-friendly\n",
    "try:\n",
    "    import nbformat\n",
    "    from nbformat import read, write, v4\n",
    "except Exception as e:\n",
    "    print('nbformat not available, you can pip install nbformat if you want to run this cell')\n",
    "\n",
    "\n",
    "def patch_notebook_metadata(nb_path: str):\n",
    "    nb = nbformat.read(nb_path, as_version=4)\n",
    "    nb.metadata.setdefault('kernelspec', {})\n",
    "    nb.metadata['kernelspec'].update({\n",
    "        'name': 'python3',\n",
    "        'display_name': 'Python 3'\n",
    "    })\n",
    "    nb.metadata.setdefault('colab', {})\n",
    "    nb.metadata['colab'].update({'name': Path(nb_path).name})\n",
    "    nbformat.write(nb, nb_path)\n",
    "    print('Patched metadata for', nb_path)\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# patch_notebook_metadata('Colab_Evaluate_and_Package.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af70e9",
   "metadata": {},
   "source": [
    "## 3) Install and verify dependencies in Colab\n",
    "\n",
    "This cell installs dependencies from `requirements.txt` located in the repo root. It then verifies PyTorch and GPU availability. If you have a custom environment or a private wheel, adapt the install commands.\n",
    "\n",
    "Note: Installing all dependencies can take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c8a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (may require GPU-specific torch wheel)\n",
    "import os\n",
    "\n",
    "# If requirements.txt exists in repo root, install it\n",
    "if os.path.exists('requirements.txt'):\n",
    "    print('Installing from requirements.txt...')\n",
    "    !pip install -r requirements.txt\n",
    "else:\n",
    "    print('No requirements.txt found. Please ensure dependencies are installed manually.')\n",
    "\n",
    "# Quick checks for torch and cuda\n",
    "try:\n",
    "    import torch\n",
    "    print('torch', torch.__version__)\n",
    "    print('CUDA available:', torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print('CUDA device count:', torch.cuda.device_count())\n",
    "        print('CUDA device name:', torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print('PyTorch not available:', e)\n",
    "\n",
    "# Optionally install PlantUML dependencies if needed for diagram rendering\n",
    "!pip install plantuml-markdown sarge >/dev/null 2>&1 || true\n",
    "print('Dependency install step complete.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016fb3dc",
   "metadata": {},
   "source": [
    "## 4) Mount Google Drive and access data\n",
    "\n",
    "Mount Drive and define `DRIVE_ROOT` where your checkpoints/results are stored. Adjust `DRIVE_RESULTS_DIR` and `DRIVE_CHECKPOINTS_DIR` to the locations you used in Drive (for example: `My Drive/GhanaSegNet/results` and `My Drive/GhanaSegNet/checkpoints`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b1c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Drive\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Default Drive paths (adjust these to your Drive layout)\n",
    "DRIVE_ROOT = '/content/drive/My Drive'\n",
    "DRIVE_PROJECT_DIR = os.path.join(DRIVE_ROOT, 'GhanaSegNet')\n",
    "DRIVE_RESULTS_DIR = os.path.join(DRIVE_PROJECT_DIR, 'results')\n",
    "DRIVE_CHECKPOINTS_DIR = os.path.join(DRIVE_PROJECT_DIR, 'checkpoints')\n",
    "\n",
    "print('Drive project dir:', DRIVE_PROJECT_DIR)\n",
    "print('Results dir:', DRIVE_RESULTS_DIR)\n",
    "print('Checkpoints dir:', DRIVE_CHECKPOINTS_DIR)\n",
    "\n",
    "# List contents for verification\n",
    "for p in [DRIVE_PROJECT_DIR, DRIVE_RESULTS_DIR, DRIVE_CHECKPOINTS_DIR]:\n",
    "    try:\n",
    "        print('\\nContents of', p)\n",
    "        for entry in os.listdir(p):\n",
    "            print(' -', entry)\n",
    "    except Exception as e:\n",
    "        print('Could not list', p, ':', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3684abc0",
   "metadata": {},
   "source": [
    "## 5) Download or stream datasets from remote sources (optional)\n",
    "\n",
    "If your dataset isn't on Drive, use this section to download it. Example shows using gdown for Google Drive shared links and wget for HTTP links. Include a checksum verification step when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4854f2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: download dataset or other artifacts\n",
    "# Uncomment and edit the lines below for your dataset urls\n",
    "# !gdown --id <file-id> -O /content/dataset.zip\n",
    "# !unzip -q /content/dataset.zip -d /content/dataset\n",
    "\n",
    "print('Dataset download section - no action performed by default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d244ae93",
   "metadata": {},
   "source": [
    "## 6) Run core analysis / model evaluation\n",
    "\n",
    "This section provides two paths:\n",
    "- Path A (quick): copy Drive `results/*.json` into the runtime and run the analysis scripts (plots & stats) using existing JSONs.\n",
    "- Path B (full): copy Drive `checkpoints/` into the runtime and run `analysis/evaluate_checkpoints_per_class.py` to produce per-class JSONs. This may require GPU and dataset access. Choose Path B only if you have checkpoints and the dataset available in the runtime.\n",
    "\n",
    "Set `USE_PATH = 'A'` or `'B'` in the next cell and adjust paths if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b63035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path selection\n",
    "USE_PATH = 'A'  # 'A' = use existing results JSONs; 'B' = evaluate checkpoints\n",
    "\n",
    "# Local workspace in Colab\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "WORK_DIR = Path('/content/GhanaSegNet')\n",
    "if WORK_DIR.exists():\n",
    "    print('Workspace already at', WORK_DIR)\n",
    "else:\n",
    "    # Copy repo from Drive_PROJECT_DIR if present, else try to `git clone` (optional)\n",
    "    if Path(DRIVE_PROJECT_DIR).exists():\n",
    "        print('Copying repo from Drive to', WORK_DIR)\n",
    "        shutil.copytree(DRIVE_PROJECT_DIR, WORK_DIR)\n",
    "    else:\n",
    "        print('Drive project dir not found - ensure you uploaded the repo or set DRIVE_PROJECT_DIR correctly')\n",
    "\n",
    "os.chdir(WORK_DIR)\n",
    "print('Current dir:', os.getcwd())\n",
    "\n",
    "# Ensure results output folder exists\n",
    "RESULTS_OUT = WORK_DIR / 'results'\n",
    "RESULTS_OUT.mkdir(exist_ok=True)\n",
    "\n",
    "# Path A: use existing JSONs from Drive\n",
    "if USE_PATH == 'A':\n",
    "    src = Path(DRIVE_RESULTS_DIR)\n",
    "    if src.exists():\n",
    "        print('Copying results from Drive results dir to runtime')\n",
    "        for f in src.glob('*.json'):\n",
    "            print(' - copying', f)\n",
    "            shutil.copy(f, RESULTS_OUT / f.name)\n",
    "    else:\n",
    "        print('Drive results directory not found; adjust DRIVE_RESULTS_DIR')\n",
    "\n",
    "# Path B: copy checkpoints and run evaluation\n",
    "if USE_PATH == 'B':\n",
    "    ckpt_src = Path(DRIVE_CHECKPOINTS_DIR)\n",
    "    if ckpt_src.exists():\n",
    "        ckpt_dest = WORK_DIR / 'checkpoints'\n",
    "        print('Copying checkpoints to runtime:', ckpt_dest)\n",
    "        if ckpt_dest.exists():\n",
    "            print('checkpoints dir already exists at runtime')\n",
    "        else:\n",
    "            shutil.copytree(ckpt_src, ckpt_dest)\n",
    "    else:\n",
    "        print('Drive checkpoints directory not found; adjust DRIVE_CHECKPOINTS_DIR')\n",
    "\n",
    "# If Path B, run the evaluation wrapper\n",
    "if USE_PATH == 'B':\n",
    "    # Adjust command depending on how evaluate_checkpoints_per_class.py expects args\n",
    "    cmd = 'python analysis/evaluate_checkpoints_per_class.py --checkpoints checkpoints --out results/per_class_summary'\n",
    "    print('Running evaluation wrapper:', cmd)\n",
    "    os.system(cmd)\n",
    "\n",
    "# After Path A, run analysis scripts that read results/*.json\n",
    "if USE_PATH == 'A':\n",
    "    print('Running analysis/model_comparison_analysis.py to generate comparison plots')\n",
    "    os.system('python analysis/model_comparison_analysis.py')\n",
    "    print('Running analysis/compute_val_iou_stats.py to compute stats')\n",
    "    os.system('python analysis/compute_val_iou_stats.py')\n",
    "\n",
    "print('Analysis step complete. Check results/ for outputs.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ff7fb",
   "metadata": {},
   "source": [
    "## 7) Save outputs, checkpoints, and artifacts to Drive\n",
    "\n",
    "This section packages small outputs (JSONs and plots) into a zip file and copies it back to Drive at the location specified below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05761c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package results (JSONs and PNGs) into a zip and copy to Drive\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "OUT_ZIP = Path('/content/results_per_class_summary_jsons.zip')\n",
    "SRC_DIRS = [Path('results')]\n",
    "\n",
    "# Create a zip of the results directory\n",
    "print('Creating zip:', OUT_ZIP)\n",
    "if OUT_ZIP.exists():\n",
    "    OUT_ZIP.unlink()\n",
    "shutil.make_archive(str(OUT_ZIP).replace('.zip',''), 'zip', 'results')\n",
    "\n",
    "# Copy to drive destination\n",
    "DRIVE_OUT = os.path.join(DRIVE_ROOT, 'GhanaSegNet_Results')\n",
    "Path(DRIVE_OUT).mkdir(parents=True, exist_ok=True)\n",
    "shutil.copy(str(OUT_ZIP), os.path.join(DRIVE_OUT, 'results_per_class_summary_jsons.zip'))\n",
    "print('Copied zip to', os.path.join(DRIVE_OUT, 'results_per_class_summary_jsons.zip'))\n",
    "\n",
    "# List created files\n",
    "print('\\nFiles in results/:')\n",
    "for f in Path('results').glob('*'):\n",
    "    print(' -', f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db425b",
   "metadata": {},
   "source": [
    "## 8) Convert/publish notebook to Colab & quick link\n",
    "\n",
    "To open this notebook in Colab from GitHub, push this repo to GitHub and use the URL:\n",
    "\n",
    "https://colab.research.google.com/github/<your-user>/<your-repo>/blob/main/Colab_Evaluate_and_Package.ipynb\n",
    "\n",
    "Or simply open the copy stored in Drive under `GhanaSegNet/Colab_Evaluate_and_Package.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1856489f",
   "metadata": {},
   "source": [
    "## 9) Automated testing: run notebook headlessly (optional)\n",
    "\n",
    "If you'd like to validate the notebook in CI, use Papermill or nbconvert. Example GitHub Actions workflow snippet is provided in the cell below (edit paths and timeouts as needed)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
