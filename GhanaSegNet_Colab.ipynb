{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricBaidoo/GhanaSegNet/blob/main/GhanaSegNet_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d998c88f",
      "metadata": {
        "id": "d998c88f"
      },
      "source": [
        "# GhanaSegNet Colab Training Notebook\n",
        "\n",
        "This notebook sets up your environment, installs dependencies, and runs your baseline training script for UNet, DeepLabV3+, and SegFormer-B0 on Colab GPU.\n",
        "\n",
        "## Setup Instructions:\n",
        "1. Run each cell in order\n",
        "2. Make sure GPU is enabled: Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "3. Your data should be uploaded to Google Drive or included in your GitHub repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "52b4adc6",
      "metadata": {
        "id": "52b4adc6",
        "outputId": "c6716446-e39a-4dd0-8962-77ecbe2f66fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (if your data is stored there)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"No GPU detected - switch to GPU runtime!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ceb2350",
      "metadata": {
        "id": "6ceb2350",
        "outputId": "b3e14047-0dcf-4c25-e8fc-55c31daa2c08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GhanaSegNet'...\n",
            "remote: Enumerating objects: 5486, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n"
          ]
        }
      ],
      "source": [
        "# Clone your GitHub repo\n",
        "!git clone https://github.com/EricBaidoo/GhanaSegNet.git\n",
        "%cd GhanaSegNet\n",
        "\n",
        "# Check if we have the expected files\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb7bd9c4",
      "metadata": {
        "id": "fb7bd9c4"
      },
      "source": [
        "## 📁 Dataset Connection Instructions\n",
        "\n",
        "**Before running the next cell:**\n",
        "\n",
        "1. **Locate your data folder in Google Drive** - Find where you uploaded your `data` folder\n",
        "2. **Check the path** - Note the exact path (e.g., `MyDrive/data` or `MyDrive/GhanaSegNet/data`)\n",
        "3. **Update the copy command** - Modify the path in the next cell to match your Drive structure\n",
        "4. **Run the cell** - The dataset will be copied to your Colab workspace\n",
        "\n",
        "**Expected folder structure after copying:**\n",
        "```\n",
        "data/\n",
        "  train/\n",
        "    images/\n",
        "    masks/\n",
        "  val/\n",
        "    images/\n",
        "    masks/\n",
        "  test/ (optional)\n",
        "    images/\n",
        "    masks/\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425c0aed",
      "metadata": {
        "id": "425c0aed"
      },
      "outputs": [],
      "source": [
        "# Download and extract data from Google Drive\n",
        "# First, upload your data.tar.gz to Google Drive, then update the path below\n",
        "\n",
        "# Option 1: If you uploaded data.tar.gz to Drive\n",
        "# !cp \"/content/drive/MyDrive/data.tar.gz\" .\n",
        "# !tar -xzf data.tar.gz\n",
        "\n",
        "# Option 2: If you uploaded the data folder directly to Drive\n",
        "            \"source\": [\n",
        "                \"# Copy your dataset from Google Drive to Colab workspace\",\n",
        "                \"# IMPORTANT: Update the path below to match where you uploaded your data folder in Google Drive\",\n",
        "                \"\",\n",
        "                \"# Option 1: If your data folder is in the root of MyDrive\",\n",
        "                \"!cp -r \"/content/drive/MyDrive/data\" .\",\n",
        "                \"\",\n",
        "                \"# Option 2: If your data folder is in a subfolder (update path as needed)\",\n",
        "                \"# !cp -r \"/content/drive/MyDrive/YourFolder/data\" .\",\n",
        "                \"\",\n",
        "                \"# Option 3: If you uploaded a compressed file\",\n",
        "                \"# !cp \"/content/drive/MyDrive/data.tar.gz\" .\",\n",
        "                \"# !tar -xzf data.tar.gz\",\n",
        "                \"\",\n",
        "                \"# Verify dataset is copied successfully\",\n",
        "                \"print(\"Checking dataset structure...\")\",\n",
        "                \"!ls -la data/\",\n",
        "                \"print(\"\n",
        "Dataset statistics:\")\",\n",
        "                \"!echo \"Train images:\" && ls data/train/images/ | wc -l\",\n",
        "                \"!echo \"Train masks:\" && ls data/train/masks/ | wc -l\",\n",
        "                \"!echo \"Val images:\" && ls data/val/images/ | wc -l 2>/dev/null || echo \"No val images found\"\",\n",
        "                \"!echo \"Val masks:\" && ls data/val/masks/ | wc -l 2>/dev/null || echo \"No val masks found\"\"\n",
        "            ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76b4f20d",
      "metadata": {
        "id": "76b4f20d"
      },
      "outputs": [],
      "source": [
        "# Alternative: Upload data directly to Colab (slower for large datasets)\n",
        "# Uncomment the lines below if you prefer direct upload\n",
        "\n",
        "# from google.colab import files\n",
        "# import zipfile\n",
        "# import os\n",
        "\n",
        "# # Upload your data.zip file\n",
        "# uploaded = files.upload()\n",
        "#\n",
        "# # Extract the uploaded file\n",
        "# for filename in uploaded.keys():\n",
        "#     if filename.endswith('.zip'):\n",
        "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "#             zip_ref.extractall('.')\n",
        "#     elif filename.endswith('.tar.gz'):\n",
        "#         !tar -xzf {filename}\n",
        "\n",
        "# print(\"Upload complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "854cd112",
      "metadata": {
        "id": "854cd112"
      },
      "outputs": [],
      "source": [
        "# Option 3: Download from Kaggle (after uploading your dataset there)\n",
        "# 1. Upload your data to Kaggle as a public dataset\n",
        "# 2. Get your Kaggle API credentials from kaggle.com/account\n",
        "# 3. Uncomment and run the code below:\n",
        "\n",
        "# !pip install kaggle\n",
        "# from google.colab import files\n",
        "#\n",
        "# # Upload your kaggle.json file\n",
        "# uploaded = files.upload()  # Upload kaggle.json\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "#\n",
        "# # Download your dataset (replace with your dataset path)\n",
        "# !kaggle datasets download yourusername/ghanasegnet-data\n",
        "# !unzip ghanasegnet-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df0f3e19",
      "metadata": {
        "id": "df0f3e19"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install additional packages that might be needed\n",
        "!pip install transformers albumentations\n",
        "\n",
        "# Verify installations\n",
        "import torch\n",
        "import torchvision\n",
        "import transformers\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Torchvision: {torchvision.__version__}\")\n",
        "print(f\"Transformers: {transformers.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea95a46b",
      "metadata": {
        "id": "ea95a46b"
      },
      "outputs": [],
      "source": [
        "# Run training - choose one of the following:\n",
        "\n",
        "# Train all models (this will take a long time)\n",
        "# !python scripts/train_baselines.py --model all --epochs 1\n",
        "\n",
        "# Train individual models:\n",
        "# UNet only\n",
        "# !python scripts/train_baselines.py --model unet --epochs 1\n",
        "\n",
        "# DeepLabV3+ only\n",
        "!python scripts/train_baselines.py --model deeplabv3plus --epochs 1\n",
        "\n",
        "# SegFormer only\n",
        "# !python scripts/train_baselines.py --model segformer --epochs 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20faabe7",
      "metadata": {
        "id": "20faabe7"
      },
      "outputs": [],
      "source": [
        "# Save results and checkpoints to Google Drive\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Create timestamped folder\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_dir = f\"/content/drive/MyDrive/GhanaSegNet_results_{timestamp}\"\n",
        "\n",
        "# Copy checkpoints and results\n",
        "if os.path.exists(\"checkpoints\"):\n",
        "    !mkdir -p \"{save_dir}\"\n",
        "    !cp -r checkpoints \"{save_dir}/\"\n",
        "    !cp -r *.json \"{save_dir}/\" 2>/dev/null || echo \"No JSON files to copy\"\n",
        "    print(f\"Results saved to: {save_dir}\")\n",
        "else:\n",
        "    print(\"No checkpoints directory found - training may have failed\")\n",
        "\n",
        "# List what was saved\n",
        "!ls -la \"{save_dir}\" 2>/dev/null || echo \"Save directory not created\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd1624e2",
      "metadata": {
        "id": "dd1624e2"
      },
      "outputs": [],
      "source": [
        "# Check training results\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Check if training summary exists\n",
        "if os.path.exists(\"checkpoints/training_summary.json\"):\n",
        "    with open(\"checkpoints/training_summary.json\", \"r\") as f:\n",
        "        results = json.load(f)\n",
        "    print(\"Training Summary:\")\n",
        "    for model, result in results.items():\n",
        "        print(f\"{model.upper()}: IoU={result['best_iou']:.4f} ({result['status']})\")\n",
        "else:\n",
        "    print(\"No training summary found yet\")\n",
        "\n",
        "# List checkpoint directories\n",
        "if os.path.exists(\"checkpoints\"):\n",
        "    print(\"\\nCheckpoint directories:\")\n",
        "    !ls -la checkpoints/\n",
        "else:\n",
        "    print(\"No checkpoints directory found\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
<<<<<<< HEAD
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (if your data is stored there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU detected - switch to GPU runtime!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since your repository is private, we'll upload the code files directly\n",
    "# Download your repository as a ZIP file from GitHub first, then upload it here\n",
    "\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"📁 Upload your GhanaSegNet project ZIP file:\")\n",
    "print(\"1. Go to https://github.com/EricBaidoo/GhanaSegNet\")\n",
    "print(\"2. Click 'Code' → 'Download ZIP'\")\n",
    "print(\"3. Upload the ZIP file below\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract the uploaded ZIP file\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        print(f\"✅ Extracted {filename}\")\n",
    "        \n",
    "        # Find the extracted folder (usually has -main suffix)\n",
    "        extracted_folders = [f for f in os.listdir('.') if f.startswith('GhanaSegNet')]\n",
    "        if extracted_folders:\n",
    "            original_name = extracted_folders[0]\n",
    "            if original_name != 'GhanaSegNet':\n",
    "                os.rename(original_name, 'GhanaSegNet')\n",
    "                print(f\"✅ Renamed {original_name} to GhanaSegNet\")\n",
    "\n",
    "# Navigate to project directory\n",
    "%cd GhanaSegNet\n",
    "\n",
    "# Check if we have the expected files\n",
    "print(\"\\n📋 Project files:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96312d1b",
   "metadata": {},
   "source": [
    "## 🔧 Repository Access Troubleshooting\n",
    "\n",
    "**If the clone failed with authentication error:**\n",
    "\n",
    "### Option A: Make Repository Public\n",
    "1. Go to your GitHub repository settings\n",
    "2. Scroll to \"Danger Zone\" \n",
    "3. Click \"Change repository visibility\" → \"Make public\"\n",
    "4. Rerun the clone cell above\n",
    "\n",
    "### Option B: Upload Code to Google Drive\n",
    "1. Download your repository as ZIP from GitHub\n",
    "2. Upload the ZIP to Google Drive\n",
    "3. Use Option 3 in the cell above to copy from Drive\n",
    "\n",
    "### Option C: Direct Upload to Colab\n",
    "1. Download repository as ZIP\n",
    "2. Use Option 2 in the cell above to upload directly\n",
    "3. The files will be extracted automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7bd9c4",
   "metadata": {},
   "source": [
    "## 📁 Dataset Connection Setup Guide\n",
    "\n",
    "### Step 1: Verify Your Google Drive Structure\n",
    "Your dataset should be in Google Drive as:\n",
    "```\n",
    "Google Drive (MyDrive)/\n",
    "└── Data/\n",
    "    ├── train/\n",
    "    │   ├── images/\n",
    "    │   └── masks/\n",
    "    ├── val/\n",
    "    │   ├── images/\n",
    "    │   └── masks/\n",
    "    └── test/ (optional)\n",
    "        ├── images/\n",
    "        └── masks/\n",
    "```\n",
    "\n",
    "### Step 2: Test the Connection\n",
    "Run the next cell to copy your \"Data\" folder from Google Drive to Colab workspace.\n",
    "\n",
    "### Step 3: Verify the Copy\n",
    "After running the copy cell, you should see:\n",
    "- Folder structure listing\n",
    "- File counts for train/val images and masks\n",
    "- No error messages\n",
    "\n",
    "### Troubleshooting:\n",
    "- **Error \"No such file or directory\"**: Check if your folder is named exactly \"Data\" (case-sensitive)\n",
    "- **Permission denied**: Make sure Google Drive is properly mounted\n",
    "- **Empty folders**: Verify your dataset was uploaded completely to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy your dataset from Google Drive to Colab workspace\n",
    "# Your dataset is stored as \"Data\" folder in Google Drive root\n",
    "\n",
    "# Copy the Data folder and rename it to data for your scripts\n",
    "!cp -r \"/content/drive/MyDrive/Data\" ./data\n",
    "\n",
    "# Verify dataset is copied successfully\n",
    "print(\"Checking dataset structure...\")\n",
    "!ls -la data/\n",
    "print(\"\\nDataset statistics:\")\n",
    "!echo \"Train images:\" && ls data/train/images/ | wc -l\n",
    "!echo \"Train masks:\" && ls data/train/masks/ | wc -l\n",
    "!echo \"Val images:\" && ls data/val/images/ | wc -l 2>/dev/null || echo \"No val images found\"\n",
    "!echo \"Val masks:\" && ls data/val/masks/ | wc -l 2>/dev/null || echo \"No val masks found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b353f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's verify your Data folder exists in Google Drive\n",
    "print(\"Checking if Data folder exists in Google Drive...\")\n",
    "!ls -la \"/content/drive/MyDrive/\" | grep -i data\n",
    "\n",
    "print(\"\\nChecking contents of Data folder...\")\n",
    "!ls -la \"/content/drive/MyDrive/Data/\" 2>/dev/null || echo \"❌ Data folder not found in Google Drive root\"\n",
    "\n",
    "print(\"\\nChecking train subfolder...\")\n",
    "!ls -la \"/content/drive/MyDrive/Data/train/\" 2>/dev/null || echo \"❌ train folder not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting: If the above verification failed, try these steps\n",
    "\n",
    "# Option A: List all folders in Google Drive to find your dataset\n",
    "print(\"All folders in Google Drive root:\")\n",
    "!ls -la \"/content/drive/MyDrive/\"\n",
    "\n",
    "# Option B: Search for folders with 'data' in the name (case-insensitive)\n",
    "print(\"\\nSearching for folders containing 'data':\")\n",
    "!find \"/content/drive/MyDrive/\" -type d -iname \"*data*\" 2>/dev/null | head -10\n",
    "\n",
    "# Option C: If your folder has a different name, update the path below\n",
    "# Uncomment and modify the line below with your actual folder name:\n",
    "# !ls -la \"/content/drive/MyDrive/YourActualFolderName/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Upload data directly to Colab (slower for large datasets)\n",
    "# Uncomment the lines below if you prefer direct upload\n",
    "\n",
    "# from google.colab import files\n",
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# # Upload your data.zip file\n",
    "# uploaded = files.upload()\n",
    "# \n",
    "# # Extract the uploaded file\n",
    "# for filename in uploaded.keys():\n",
    "#     if filename.endswith('.zip'):\n",
    "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#             zip_ref.extractall('.')\n",
    "#     elif filename.endswith('.tar.gz'):\n",
    "#         !tar -xzf {filename}\n",
    "\n",
    "# print(\"Upload complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854cd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Download from Kaggle (after uploading your dataset there)\n",
    "# 1. Upload your data to Kaggle as a public dataset\n",
    "# 2. Get your Kaggle API credentials from kaggle.com/account\n",
    "# 3. Uncomment and run the code below:\n",
    "\n",
    "# !pip install kaggle\n",
    "# from google.colab import files\n",
    "# \n",
    "# # Upload your kaggle.json file\n",
    "# uploaded = files.upload()  # Upload kaggle.json\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# \n",
    "# # Download your dataset (replace with your dataset path)\n",
    "# !kaggle datasets download yourusername/ghanasegnet-data\n",
    "# !unzip ghanasegnet-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Install additional packages that might be needed\n",
    "!pip install transformers albumentations\n",
    "\n",
    "# Verify installations\n",
    "import torch\n",
    "import torchvision\n",
    "import transformers\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Torchvision: {torchvision.__version__}\")\n",
    "print(f\"Transformers: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training - choose one of the following:\n",
    "\n",
    "# Train all models (this will take a long time)\n",
    "# !python scripts/train_baselines.py --model all --epochs 1\n",
    "\n",
    "# Train individual models:\n",
    "# UNet only\n",
    "# !python scripts/train_baselines.py --model unet --epochs 1\n",
    "\n",
    "# DeepLabV3+ only  \n",
    "!python scripts/train_baselines.py --model deeplabv3plus --epochs 1\n",
    "\n",
    "# SegFormer only\n",
    "# !python scripts/train_baselines.py --model segformer --epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20faabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and checkpoints to Google Drive\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamped folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = f\"/content/drive/MyDrive/GhanaSegNet_results_{timestamp}\"\n",
    "\n",
    "# Copy checkpoints and results\n",
    "if os.path.exists(\"checkpoints\"):\n",
    "    !mkdir -p \"{save_dir}\"\n",
    "    !cp -r checkpoints \"{save_dir}/\"\n",
    "    !cp -r *.json \"{save_dir}/\" 2>/dev/null || echo \"No JSON files to copy\"\n",
    "    print(f\"Results saved to: {save_dir}\")\n",
    "else:\n",
    "    print(\"No checkpoints directory found - training may have failed\")\n",
    "\n",
    "# List what was saved\n",
    "!ls -la \"{save_dir}\" 2>/dev/null || echo \"Save directory not created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1624e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Check if training summary exists\n",
    "if os.path.exists(\"checkpoints/training_summary.json\"):\n",
    "    with open(\"checkpoints/training_summary.json\", \"r\") as f:\n",
    "        results = json.load(f)\n",
    "    print(\"Training Summary:\")\n",
    "    for model, result in results.items():\n",
    "        print(f\"{model.upper()}: IoU={result['best_iou']:.4f} ({result['status']})\")\n",
    "else:\n",
    "    print(\"No training summary found yet\")\n",
    "\n",
    "# List checkpoint directories\n",
    "if os.path.exists(\"checkpoints\"):\n",
    "    print(\"\\nCheckpoint directories:\")\n",
    "    !ls -la checkpoints/\n",
    "else:\n",
    "    print(\"No checkpoints directory found\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
=======
  "nbformat": 4,
  "nbformat_minor": 5
}
>>>>>>> 5e6168d6d0eddc972dd2182a244686cf5cddff0e
