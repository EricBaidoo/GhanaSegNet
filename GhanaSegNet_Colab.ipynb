{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d998c88f",
   "metadata": {},
   "source": [
    "# GhanaSegNet Colab Training Notebook\n",
    "\n",
    "This notebook sets up your environment, installs dependencies, and runs your baseline training script for UNet, DeepLabV3+, and SegFormer-B0 on Colab GPU.\n",
    "\n",
    "## Setup Instructions:\n",
    "1. Run each cell in order\n",
    "2. Make sure GPU is enabled: Runtime > Change runtime type > Hardware accelerator > GPU\n",
    "3. Your data should be uploaded to Google Drive or included in your GitHub repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (if your data is stored there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU detected - switch to GPU runtime!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your GitHub repo\n",
    "!git clone https://github.com/EricBaidoo/GhanaSegNet.git\n",
    "%cd GhanaSegNet\n",
    "\n",
    "# Check if we have the expected files\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract data from Google Drive\n",
    "# First, upload your data.tar.gz to Google Drive, then update the path below\n",
    "\n",
    "# Option 1: If you uploaded data.tar.gz to Drive\n",
    "# !cp \"/content/drive/MyDrive/data.tar.gz\" .\n",
    "# !tar -xzf data.tar.gz\n",
    "\n",
    "# Option 2: If you uploaded the data folder directly to Drive\n",
    "!cp -r \"/content/drive/MyDrive/data\" .\n",
    "\n",
    "# Verify data is present\n",
    "!ls -la data/\n",
    "!echo \"Train images:\" && ls data/train/images/ | wc -l\n",
    "!echo \"Train masks:\" && ls data/train/masks/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Upload data directly to Colab (slower for large datasets)\n",
    "# Uncomment the lines below if you prefer direct upload\n",
    "\n",
    "# from google.colab import files\n",
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# # Upload your data.zip file\n",
    "# uploaded = files.upload()\n",
    "# \n",
    "# # Extract the uploaded file\n",
    "# for filename in uploaded.keys():\n",
    "#     if filename.endswith('.zip'):\n",
    "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#             zip_ref.extractall('.')\n",
    "#     elif filename.endswith('.tar.gz'):\n",
    "#         !tar -xzf {filename}\n",
    "\n",
    "# print(\"Upload complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854cd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Download from Kaggle (after uploading your dataset there)\n",
    "# 1. Upload your data to Kaggle as a public dataset\n",
    "# 2. Get your Kaggle API credentials from kaggle.com/account\n",
    "# 3. Uncomment and run the code below:\n",
    "\n",
    "# !pip install kaggle\n",
    "# from google.colab import files\n",
    "# \n",
    "# # Upload your kaggle.json file\n",
    "# uploaded = files.upload()  # Upload kaggle.json\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# \n",
    "# # Download your dataset (replace with your dataset path)\n",
    "# !kaggle datasets download yourusername/ghanasegnet-data\n",
    "# !unzip ghanasegnet-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Install additional packages that might be needed\n",
    "!pip install transformers albumentations\n",
    "\n",
    "# Verify installations\n",
    "import torch\n",
    "import torchvision\n",
    "import transformers\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Torchvision: {torchvision.__version__}\")\n",
    "print(f\"Transformers: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training - choose one of the following:\n",
    "\n",
    "# Train all models (this will take a long time)\n",
    "# !python scripts/train_baselines.py --model all --epochs 1\n",
    "\n",
    "# Train individual models:\n",
    "# UNet only\n",
    "# !python scripts/train_baselines.py --model unet --epochs 1\n",
    "\n",
    "# DeepLabV3+ only  \n",
    "!python scripts/train_baselines.py --model deeplabv3plus --epochs 1\n",
    "\n",
    "# SegFormer only\n",
    "# !python scripts/train_baselines.py --model segformer --epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20faabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and checkpoints to Google Drive\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamped folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = f\"/content/drive/MyDrive/GhanaSegNet_results_{timestamp}\"\n",
    "\n",
    "# Copy checkpoints and results\n",
    "if os.path.exists(\"checkpoints\"):\n",
    "    !mkdir -p \"{save_dir}\"\n",
    "    !cp -r checkpoints \"{save_dir}/\"\n",
    "    !cp -r *.json \"{save_dir}/\" 2>/dev/null || echo \"No JSON files to copy\"\n",
    "    print(f\"Results saved to: {save_dir}\")\n",
    "else:\n",
    "    print(\"No checkpoints directory found - training may have failed\")\n",
    "\n",
    "# List what was saved\n",
    "!ls -la \"{save_dir}\" 2>/dev/null || echo \"Save directory not created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1624e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Check if training summary exists\n",
    "if os.path.exists(\"checkpoints/training_summary.json\"):\n",
    "    with open(\"checkpoints/training_summary.json\", \"r\") as f:\n",
    "        results = json.load(f)\n",
    "    print(\"Training Summary:\")\n",
    "    for model, result in results.items():\n",
    "        print(f\"{model.upper()}: IoU={result['best_iou']:.4f} ({result['status']})\")\n",
    "else:\n",
    "    print(\"No training summary found yet\")\n",
    "\n",
    "# List checkpoint directories\n",
    "if os.path.exists(\"checkpoints\"):\n",
    "    print(\"\\nCheckpoint directories:\")\n",
    "    !ls -la checkpoints/\n",
    "else:\n",
    "    print(\"No checkpoints directory found\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
