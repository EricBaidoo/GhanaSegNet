{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricBaidoo/GhanaSegNet/blob/main/GhanaSegNet_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d998c88f",
      "metadata": {
        "id": "d998c88f"
      },
      "source": [
        "# GhanaSegNet Colab Training Notebook\n",
        "\n",
        "This notebook sets up your environment, installs dependencies, and runs your baseline training script for UNet, DeepLabV3+, and SegFormer-B0 on Colab GPU.\n",
        "\n",
        "## Setup Instructions:\n",
        "1. Run each cell in order\n",
        "2. Make sure GPU is enabled: Runtime > Change runtime type > Hardware accelerator > GPU\n",
        "3. Your data should be uploaded to Google Drive or included in your GitHub repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "52b4adc6",
      "metadata": {
        "id": "52b4adc6",
        "outputId": "c6716446-e39a-4dd0-8962-77ecbe2f66fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (if your data is stored there)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"No GPU detected - switch to GPU runtime!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ceb2350",
      "metadata": {
        "id": "6ceb2350",
        "outputId": "b3e14047-0dcf-4c25-e8fc-55c31daa2c08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GhanaSegNet'...\n",
            "remote: Enumerating objects: 5486, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n"
          ]
        }
      ],
      "source": [
        "# Clone your GitHub repo\n",
        "!git clone https://github.com/EricBaidoo/GhanaSegNet.git\n",
        "%cd GhanaSegNet\n",
        "\n",
        "# Check if we have the expected files\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb7bd9c4",
      "metadata": {
        "id": "fb7bd9c4"
      },
      "source": [
        "## ðŸ“ Dataset Connection Instructions\n",
        "\n",
        "**Before running the next cell:**\n",
        "\n",
        "1. **Locate your data folder in Google Drive** - Find where you uploaded your `data` folder\n",
        "2. **Check the path** - Note the exact path (e.g., `MyDrive/data` or `MyDrive/GhanaSegNet/data`)\n",
        "3. **Update the copy command** - Modify the path in the next cell to match your Drive structure\n",
        "4. **Run the cell** - The dataset will be copied to your Colab workspace\n",
        "\n",
        "**Expected folder structure after copying:**\n",
        "```\n",
        "data/\n",
        "  train/\n",
        "    images/\n",
        "    masks/\n",
        "  val/\n",
        "    images/\n",
        "    masks/\n",
        "  test/ (optional)\n",
        "    images/\n",
        "    masks/\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "425c0aed",
      "metadata": {
        "id": "425c0aed"
      },
      "outputs": [],
      "source": [
        "# Download and extract data from Google Drive\n",
        "# First, upload your data.tar.gz to Google Drive, then update the path below\n",
        "\n",
        "# Option 1: If you uploaded data.tar.gz to Drive\n",
        "# !cp \"/content/drive/MyDrive/data.tar.gz\" .\n",
        "# !tar -xzf data.tar.gz\n",
        "\n",
        "# Option 2: If you uploaded the data folder directly to Drive\n",
        "            \"source\": [\n",
        "                \"# Copy your dataset from Google Drive to Colab workspace\",\n",
        "                \"# IMPORTANT: Update the path below to match where you uploaded your data folder in Google Drive\",\n",
        "                \"\",\n",
        "                \"# Option 1: If your data folder is in the root of MyDrive\",\n",
        "                \"!cp -r \"/content/drive/MyDrive/data\" .\",\n",
        "                \"\",\n",
        "                \"# Option 2: If your data folder is in a subfolder (update path as needed)\",\n",
        "                \"# !cp -r \"/content/drive/MyDrive/YourFolder/data\" .\",\n",
        "                \"\",\n",
        "                \"# Option 3: If you uploaded a compressed file\",\n",
        "                \"# !cp \"/content/drive/MyDrive/data.tar.gz\" .\",\n",
        "                \"# !tar -xzf data.tar.gz\",\n",
        "                \"\",\n",
        "                \"# Verify dataset is copied successfully\",\n",
        "                \"print(\"Checking dataset structure...\")\",\n",
        "                \"!ls -la data/\",\n",
        "                \"print(\"\n",
        "Dataset statistics:\")\",\n",
        "                \"!echo \"Train images:\" && ls data/train/images/ | wc -l\",\n",
        "                \"!echo \"Train masks:\" && ls data/train/masks/ | wc -l\",\n",
        "                \"!echo \"Val images:\" && ls data/val/images/ | wc -l 2>/dev/null || echo \"No val images found\"\",\n",
        "                \"!echo \"Val masks:\" && ls data/val/masks/ | wc -l 2>/dev/null || echo \"No val masks found\"\"\n",
        "            ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76b4f20d",
      "metadata": {
        "id": "76b4f20d"
      },
      "outputs": [],
      "source": [
        "# Alternative: Upload data directly to Colab (slower for large datasets)\n",
        "# Uncomment the lines below if you prefer direct upload\n",
        "\n",
        "# from google.colab import files\n",
        "# import zipfile\n",
        "# import os\n",
        "\n",
        "# # Upload your data.zip file\n",
        "# uploaded = files.upload()\n",
        "#\n",
        "# # Extract the uploaded file\n",
        "# for filename in uploaded.keys():\n",
        "#     if filename.endswith('.zip'):\n",
        "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "#             zip_ref.extractall('.')\n",
        "#     elif filename.endswith('.tar.gz'):\n",
        "#         !tar -xzf {filename}\n",
        "\n",
        "# print(\"Upload complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "854cd112",
      "metadata": {
        "id": "854cd112"
      },
      "outputs": [],
      "source": [
        "# Option 3: Download from Kaggle (after uploading your dataset there)\n",
        "# 1. Upload your data to Kaggle as a public dataset\n",
        "# 2. Get your Kaggle API credentials from kaggle.com/account\n",
        "# 3. Uncomment and run the code below:\n",
        "\n",
        "# !pip install kaggle\n",
        "# from google.colab import files\n",
        "#\n",
        "# # Upload your kaggle.json file\n",
        "# uploaded = files.upload()  # Upload kaggle.json\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "#\n",
        "# # Download your dataset (replace with your dataset path)\n",
        "# !kaggle datasets download yourusername/ghanasegnet-data\n",
        "# !unzip ghanasegnet-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df0f3e19",
      "metadata": {
        "id": "df0f3e19"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install additional packages that might be needed\n",
        "!pip install transformers albumentations\n",
        "\n",
        "# Verify installations\n",
        "import torch\n",
        "import torchvision\n",
        "import transformers\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Torchvision: {torchvision.__version__}\")\n",
        "print(f\"Transformers: {transformers.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea95a46b",
      "metadata": {
        "id": "ea95a46b"
      },
      "outputs": [],
      "source": [
        "# Run training - choose one of the following:\n",
        "\n",
        "# Train all models (this will take a long time)\n",
        "# !python scripts/train_baselines.py --model all --epochs 1\n",
        "\n",
        "# Train individual models:\n",
        "# UNet only\n",
        "# !python scripts/train_baselines.py --model unet --epochs 1\n",
        "\n",
        "# DeepLabV3+ only\n",
        "!python scripts/train_baselines.py --model deeplabv3plus --epochs 1\n",
        "\n",
        "# SegFormer only\n",
        "# !python scripts/train_baselines.py --model segformer --epochs 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20faabe7",
      "metadata": {
        "id": "20faabe7"
      },
      "outputs": [],
      "source": [
        "# Save results and checkpoints to Google Drive\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Create timestamped folder\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "save_dir = f\"/content/drive/MyDrive/GhanaSegNet_results_{timestamp}\"\n",
        "\n",
        "# Copy checkpoints and results\n",
        "if os.path.exists(\"checkpoints\"):\n",
        "    !mkdir -p \"{save_dir}\"\n",
        "    !cp -r checkpoints \"{save_dir}/\"\n",
        "    !cp -r *.json \"{save_dir}/\" 2>/dev/null || echo \"No JSON files to copy\"\n",
        "    print(f\"Results saved to: {save_dir}\")\n",
        "else:\n",
        "    print(\"No checkpoints directory found - training may have failed\")\n",
        "\n",
        "# List what was saved\n",
        "!ls -la \"{save_dir}\" 2>/dev/null || echo \"Save directory not created\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd1624e2",
      "metadata": {
        "id": "dd1624e2"
      },
      "outputs": [],
      "source": [
        "# Check training results\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Check if training summary exists\n",
        "if os.path.exists(\"checkpoints/training_summary.json\"):\n",
        "    with open(\"checkpoints/training_summary.json\", \"r\") as f:\n",
        "        results = json.load(f)\n",
        "    print(\"Training Summary:\")\n",
        "    for model, result in results.items():\n",
        "        print(f\"{model.upper()}: IoU={result['best_iou']:.4f} ({result['status']})\")\n",
        "else:\n",
        "    print(\"No training summary found yet\")\n",
        "\n",
        "# List checkpoint directories\n",
        "if os.path.exists(\"checkpoints\"):\n",
        "    print(\"\\nCheckpoint directories:\")\n",
        "    !ls -la checkpoints/\n",
        "else:\n",
        "    print(\"No checkpoints directory found\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
<<<<<<< HEAD
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (if your data is stored there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU detected - switch to GPU runtime!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceb2350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since your repository is private, we'll upload the code files directly\n",
    "# Download your repository as a ZIP file from GitHub first, then upload it here\n",
    "\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"ðŸ“ Upload your GhanaSegNet project ZIP file:\")\n",
    "print(\"1. Go to https://github.com/EricBaidoo/GhanaSegNet\")\n",
    "print(\"2. Click 'Code' â†’ 'Download ZIP'\")\n",
    "print(\"3. Upload the ZIP file below\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract the uploaded ZIP file\n",
    "for filename in uploaded.keys():\n",
    "    if filename.endswith('.zip'):\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall('.')\n",
    "        print(f\"âœ… Extracted {filename}\")\n",
    "        \n",
    "        # Find the extracted folder (usually has -main suffix)\n",
    "        extracted_folders = [f for f in os.listdir('.') if f.startswith('GhanaSegNet')]\n",
    "        if extracted_folders:\n",
    "            original_name = extracted_folders[0]\n",
    "            if original_name != 'GhanaSegNet':\n",
    "                os.rename(original_name, 'GhanaSegNet')\n",
    "                print(f\"âœ… Renamed {original_name} to GhanaSegNet\")\n",
    "\n",
    "# Navigate to project directory\n",
    "%cd GhanaSegNet\n",
    "\n",
    "# Check if we have the expected files\n",
    "print(\"\\nðŸ“‹ Project files:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96312d1b",
   "metadata": {},
   "source": [
    "## ðŸ”§ Repository Access Troubleshooting\n",
    "\n",
    "**If the clone failed with authentication error:**\n",
    "\n",
    "### Option A: Make Repository Public\n",
    "1. Go to your GitHub repository settings\n",
    "2. Scroll to \"Danger Zone\" \n",
    "3. Click \"Change repository visibility\" â†’ \"Make public\"\n",
    "4. Rerun the clone cell above\n",
    "\n",
    "### Option B: Upload Code to Google Drive\n",
    "1. Download your repository as ZIP from GitHub\n",
    "2. Upload the ZIP to Google Drive\n",
    "3. Use Option 3 in the cell above to copy from Drive\n",
    "\n",
    "### Option C: Direct Upload to Colab\n",
    "1. Download repository as ZIP\n",
    "2. Use Option 2 in the cell above to upload directly\n",
    "3. The files will be extracted automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7bd9c4",
   "metadata": {},
   "source": [
    "## ðŸ“ Dataset Connection Setup Guide\n",
    "\n",
    "### Step 1: Verify Your Google Drive Structure\n",
    "Your dataset should be in Google Drive as:\n",
    "```\n",
    "Google Drive (MyDrive)/\n",
    "â””â”€â”€ Data/\n",
    "    â”œâ”€â”€ train/\n",
    "    â”‚   â”œâ”€â”€ images/\n",
    "    â”‚   â””â”€â”€ masks/\n",
    "    â”œâ”€â”€ val/\n",
    "    â”‚   â”œâ”€â”€ images/\n",
    "    â”‚   â””â”€â”€ masks/\n",
    "    â””â”€â”€ test/ (optional)\n",
    "        â”œâ”€â”€ images/\n",
    "        â””â”€â”€ masks/\n",
    "```\n",
    "\n",
    "### Step 2: Test the Connection\n",
    "Run the next cell to copy your \"Data\" folder from Google Drive to Colab workspace.\n",
    "\n",
    "### Step 3: Verify the Copy\n",
    "After running the copy cell, you should see:\n",
    "- Folder structure listing\n",
    "- File counts for train/val images and masks\n",
    "- No error messages\n",
    "\n",
    "### Troubleshooting:\n",
    "- **Error \"No such file or directory\"**: Check if your folder is named exactly \"Data\" (case-sensitive)\n",
    "- **Permission denied**: Make sure Google Drive is properly mounted\n",
    "- **Empty folders**: Verify your dataset was uploaded completely to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c0aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy your dataset from Google Drive to Colab workspace\n",
    "# Your dataset is stored as \"Data\" folder in Google Drive root\n",
    "\n",
    "# Copy the Data folder and rename it to data for your scripts\n",
    "!cp -r \"/content/drive/MyDrive/Data\" ./data\n",
    "\n",
    "# Verify dataset is copied successfully\n",
    "print(\"Checking dataset structure...\")\n",
    "!ls -la data/\n",
    "print(\"\\nDataset statistics:\")\n",
    "!echo \"Train images:\" && ls data/train/images/ | wc -l\n",
    "!echo \"Train masks:\" && ls data/train/masks/ | wc -l\n",
    "!echo \"Val images:\" && ls data/val/images/ | wc -l 2>/dev/null || echo \"No val images found\"\n",
    "!echo \"Val masks:\" && ls data/val/masks/ | wc -l 2>/dev/null || echo \"No val masks found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b353f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's verify your Data folder exists in Google Drive\n",
    "print(\"Checking if Data folder exists in Google Drive...\")\n",
    "!ls -la \"/content/drive/MyDrive/\" | grep -i data\n",
    "\n",
    "print(\"\\nChecking contents of Data folder...\")\n",
    "!ls -la \"/content/drive/MyDrive/Data/\" 2>/dev/null || echo \"âŒ Data folder not found in Google Drive root\"\n",
    "\n",
    "print(\"\\nChecking train subfolder...\")\n",
    "!ls -la \"/content/drive/MyDrive/Data/train/\" 2>/dev/null || echo \"âŒ train folder not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Troubleshooting: If the above verification failed, try these steps\n",
    "\n",
    "# Option A: List all folders in Google Drive to find your dataset\n",
    "print(\"All folders in Google Drive root:\")\n",
    "!ls -la \"/content/drive/MyDrive/\"\n",
    "\n",
    "# Option B: Search for folders with 'data' in the name (case-insensitive)\n",
    "print(\"\\nSearching for folders containing 'data':\")\n",
    "!find \"/content/drive/MyDrive/\" -type d -iname \"*data*\" 2>/dev/null | head -10\n",
    "\n",
    "# Option C: If your folder has a different name, update the path below\n",
    "# Uncomment and modify the line below with your actual folder name:\n",
    "# !ls -la \"/content/drive/MyDrive/YourActualFolderName/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b4f20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Upload data directly to Colab (slower for large datasets)\n",
    "# Uncomment the lines below if you prefer direct upload\n",
    "\n",
    "# from google.colab import files\n",
    "# import zipfile\n",
    "# import os\n",
    "\n",
    "# # Upload your data.zip file\n",
    "# uploaded = files.upload()\n",
    "# \n",
    "# # Extract the uploaded file\n",
    "# for filename in uploaded.keys():\n",
    "#     if filename.endswith('.zip'):\n",
    "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#             zip_ref.extractall('.')\n",
    "#     elif filename.endswith('.tar.gz'):\n",
    "#         !tar -xzf {filename}\n",
    "\n",
    "# print(\"Upload complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854cd112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Download from Kaggle (after uploading your dataset there)\n",
    "# 1. Upload your data to Kaggle as a public dataset\n",
    "# 2. Get your Kaggle API credentials from kaggle.com/account\n",
    "# 3. Uncomment and run the code below:\n",
    "\n",
    "# !pip install kaggle\n",
    "# from google.colab import files\n",
    "# \n",
    "# # Upload your kaggle.json file\n",
    "# uploaded = files.upload()  # Upload kaggle.json\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# \n",
    "# # Download your dataset (replace with your dataset path)\n",
    "# !kaggle datasets download yourusername/ghanasegnet-data\n",
    "# !unzip ghanasegnet-data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f3e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Install additional packages that might be needed\n",
    "!pip install transformers albumentations\n",
    "\n",
    "# Verify installations\n",
    "import torch\n",
    "import torchvision\n",
    "import transformers\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"Torchvision: {torchvision.__version__}\")\n",
    "print(f\"Transformers: {transformers.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95a46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training - choose one of the following:\n",
    "\n",
    "# Train all models (this will take a long time)\n",
    "# !python scripts/train_baselines.py --model all --epochs 1\n",
    "\n",
    "# Train individual models:\n",
    "# UNet only\n",
    "# !python scripts/train_baselines.py --model unet --epochs 1\n",
    "\n",
    "# DeepLabV3+ only  \n",
    "!python scripts/train_baselines.py --model deeplabv3plus --epochs 1\n",
    "\n",
    "# SegFormer only\n",
    "# !python scripts/train_baselines.py --model segformer --epochs 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20faabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results and checkpoints to Google Drive\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Create timestamped folder\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "save_dir = f\"/content/drive/MyDrive/GhanaSegNet_results_{timestamp}\"\n",
    "\n",
    "# Copy checkpoints and results\n",
    "if os.path.exists(\"checkpoints\"):\n",
    "    !mkdir -p \"{save_dir}\"\n",
    "    !cp -r checkpoints \"{save_dir}/\"\n",
    "    !cp -r *.json \"{save_dir}/\" 2>/dev/null || echo \"No JSON files to copy\"\n",
    "    print(f\"Results saved to: {save_dir}\")\n",
    "else:\n",
    "    print(\"No checkpoints directory found - training may have failed\")\n",
    "\n",
    "# List what was saved\n",
    "!ls -la \"{save_dir}\" 2>/dev/null || echo \"Save directory not created\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1624e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check training results\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Check if training summary exists\n",
    "if os.path.exists(\"checkpoints/training_summary.json\"):\n",
    "    with open(\"checkpoints/training_summary.json\", \"r\") as f:\n",
    "        results = json.load(f)\n",
    "    print(\"Training Summary:\")\n",
    "    for model, result in results.items():\n",
    "        print(f\"{model.upper()}: IoU={result['best_iou']:.4f} ({result['status']})\")\n",
    "else:\n",
    "    print(\"No training summary found yet\")\n",
    "\n",
    "# List checkpoint directories\n",
    "if os.path.exists(\"checkpoints\"):\n",
    "    print(\"\\nCheckpoint directories:\")\n",
    "    !ls -la checkpoints/\n",
    "else:\n",
    "    print(\"No checkpoints directory found\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
=======
  "nbformat": 4,
  "nbformat_minor": 5
}
>>>>>>> 5e6168d6d0eddc972dd2182a244686cf5cddff0e
