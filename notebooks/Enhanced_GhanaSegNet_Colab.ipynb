{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1125a548",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/EricBaidoo/GhanaSegNet/blob/main/notebooks/Enhanced_GhanaSegNet_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0576ce",
   "metadata": {},
   "source": [
    "# Enhanced GhanaSegNet - 30% mIoU Target\n",
    "\n",
    "**Objective:** Train the Enhanced GhanaSegNet architecture to achieve 30% mIoU\n",
    "\n",
    "**Model:** Enhanced GhanaSegNet (FPN + Advanced ASPP + Cross-Attention)\n",
    "- **Parameters:** 10.5M\n",
    "- **Architecture:** EfficientNet-B0 + FPN + Enhanced ASPP + Cross-Attention Transformer\n",
    "- **Target Performance:** 30% mIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79163045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and check GPU\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No GPU detected - switch to GPU runtime for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/EricBaidoo/GhanaSegNet.git\n",
    "%cd GhanaSegNet\n",
    "\n",
    "# Verify repository structure\n",
    "print(\"Repository contents:\")\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d977fd6",
   "metadata": {},
   "source": [
    "## Dataset Setup\n",
    "\n",
    "**Before running the next cell:**\n",
    "\n",
    "1. **Upload your dataset to Google Drive** in this structure:\n",
    "   ```\n",
    "   MyDrive/\n",
    "     dataset/\n",
    "       train/\n",
    "         images/\n",
    "         masks/\n",
    "       val/\n",
    "         images/\n",
    "         masks/\n",
    "   ```\n",
    "\n",
    "2. **Update the path below** if your dataset is in a different location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d302821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset from Google Drive\n",
    "DATASET_PATH = \"/content/drive/MyDrive/dataset\"\n",
    "LOCAL_DATA_PATH = \"/content/GhanaSegNet/data\"\n",
    "\n",
    "print(f\"Copying dataset from: {DATASET_PATH}\")\n",
    "!cp -r \"{DATASET_PATH}\" data\n",
    "\n",
    "# Verify dataset structure\n",
    "print(\"\\nüìä Dataset verification:\")\n",
    "!echo \"Train images:\" && ls data/train/images/ | wc -l\n",
    "!echo \"Train masks:\" && ls data/train/masks/ | wc -l\n",
    "!echo \"Val images:\" && ls data/val/images/ | wc -l\n",
    "!echo \"Val masks:\" && ls data/val/masks/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d9fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"üîß Installing dependencies...\")\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install efficientnet-pytorch opencv-python pillow tqdm\n",
    "\n",
    "# Verify installations\n",
    "import torch\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA: {torch.cuda.is_available()}\")\n",
    "print(\"‚úÖ EfficientNet installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98424619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify Enhanced GhanaSegNet can be imported\n",
    "import os\n",
    "os.chdir('/content/GhanaSegNet')\n",
    "\n",
    "try:\n",
    "    from models.ghanasegnet import GhanaSegNet\n",
    "    from utils.losses import CombinedLoss\n",
    "    from utils.metrics import compute_iou\n",
    "    \n",
    "    # Test model creation\n",
    "    model = GhanaSegNet(num_classes=6)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    print(\"‚úÖ Enhanced GhanaSegNet imported successfully\")\n",
    "    print(f\"‚úÖ Model parameters: {total_params:,} (Target: ~10.5M)\")\n",
    "    print(\"‚úÖ Enhanced loss function ready\")\n",
    "    print(\"‚úÖ All systems ready for 30% mIoU training!\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189bd5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup auto-save to Google Drive\n",
    "from google.colab import drive\n",
    "import shutil\n",
    "\n",
    "# Create results directory\n",
    "RESULTS_DIR = '/content/drive/MyDrive/Enhanced_GhanaSegNet_Results'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "def save_results():\n",
    "    \"\"\"Save training results to Google Drive\"\"\"\n",
    "    if os.path.exists('checkpoints/ghanasegnet'):\n",
    "        shutil.copytree('checkpoints/ghanasegnet', f'{RESULTS_DIR}/checkpoints', dirs_exist_ok=True)\n",
    "        print(f\"‚úÖ Results saved to: {RESULTS_DIR}\")\n",
    "    else:\n",
    "        print(\"‚ùå No results to save\")\n",
    "\n",
    "print(f\"üìÅ Auto-save configured to: {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2236a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Enhanced GhanaSegNet - Quick Test (15 epochs)\n",
    "from scripts.train_baselines import train_model\n",
    "\n",
    "# Training configuration for 30% mIoU target\n",
    "config = {\n",
    "    'epochs': 15,\n",
    "    'batch_size': 8,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'num_classes': 6,\n",
    "    'custom_seed': 789,  # Enhanced GhanaSegNet seed\n",
    "    'benchmark_mode': True,\n",
    "    'dataset_path': 'data',\n",
    "    'device': 'cuda',\n",
    "    'timestamp': '2025-10-12',\n",
    "    'note': 'Enhanced GhanaSegNet - 30% mIoU Target'\n",
    "}\n",
    "\n",
    "print(\"üöÄ Starting Enhanced GhanaSegNet Training...\")\n",
    "print(\"üéØ Target: 30% mIoU\")\n",
    "print(f\"üìã Config: {config}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    result = train_model('ghanasegnet', config)\n",
    "    \n",
    "    # Display results\n",
    "    best_iou = result['best_iou']\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üéØ TRAINING COMPLETED!\")\n",
    "    print(f\"üìä Best IoU: {best_iou:.4f} ({best_iou*100:.2f}%)\")\n",
    "    \n",
    "    if best_iou >= 0.30:\n",
    "        print(\"üèÜ 30% mIoU TARGET ACHIEVED! üéâ\")\n",
    "    elif best_iou >= 0.25:\n",
    "        print(f\"üìà Strong Progress! {(best_iou*100):.1f}% (Target: 30%)\")\n",
    "    else:\n",
    "        print(f\"üìä Current: {(best_iou*100):.1f}% (Target: 30%) - Consider full training\")\n",
    "    \n",
    "    # Auto-save results\n",
    "    save_results()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c016b",
   "metadata": {},
   "source": [
    "## Full Training (80+ epochs)\n",
    "\n",
    "If the quick test shows promising results, run full training by changing `'epochs': 80` in the config above.\n",
    "\n",
    "**Expected timeline:**\n",
    "- 15 epochs: ~10-15 minutes (quick validation)\n",
    "- 80 epochs: ~45-60 minutes (full training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze results\n",
    "import json\n",
    "import os\n",
    "\n",
    "if os.path.exists('checkpoints/ghanasegnet/training_history.json'):\n",
    "    with open('checkpoints/ghanasegnet/training_history.json', 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    print(\"üìà Training History:\")\n",
    "    print(f\"üìä Final IoU: {history[-1]['val_iou']:.4f}\")\n",
    "    print(f\"üìä Final Accuracy: {history[-1]['val_accuracy']:.4f}\")\n",
    "    print(f\"üìä Best Epoch: {max(history, key=lambda x: x['val_iou'])['epoch']}\")\n",
    "    \n",
    "    # Plot training curves if possible\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        epochs = [h['epoch'] for h in history]\n",
    "        val_iou = [h['val_iou'] for h in history]\n",
    "        train_loss = [h['train_loss'] for h in history]\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        ax1.plot(epochs, val_iou, 'b-', label='Validation IoU')\n",
    "        ax1.axhline(y=0.30, color='r', linestyle='--', label='30% Target')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('IoU')\n",
    "        ax1.set_title('Enhanced GhanaSegNet - IoU Progress')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        ax2.plot(epochs, train_loss, 'g-', label='Training Loss')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Loss')\n",
    "        ax2.set_title('Training Loss')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"üìä Install matplotlib for training curves: !pip install matplotlib\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No training history found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a9b53c",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "**Enhanced GhanaSegNet Architecture:**\n",
    "- **Backbone:** EfficientNet-B0 (pretrained)\n",
    "- **Decoder:** FPN-style multi-scale fusion\n",
    "- **ASPP:** Advanced with 4 dilation rates [2,4,8,16]\n",
    "- **Attention:** Cross-attention transformer (8+4 heads)\n",
    "- **Loss:** Multi-scale supervision + Dice + Focal + Boundary\n",
    "- **Parameters:** ~10.5M\n",
    "- **Target:** 30% mIoU\n",
    "\n",
    "**Key Innovations:**\n",
    "1. Multi-scale feature pyramid network\n",
    "2. Cross-scale attention mechanism\n",
    "3. Enhanced ASPP with depth-wise convolutions\n",
    "4. Multi-scale auxiliary supervision\n",
    "5. Class-balanced loss for food segmentation"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
