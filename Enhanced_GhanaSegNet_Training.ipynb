{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a8b1e9",
   "metadata": {},
   "source": [
    "# üöÄ Enhanced GhanaSegNet Training - 30% mIoU Target\n",
    "\n",
    "**Objective**: Train the enhanced GhanaSegNet architecture to achieve 30% mIoU performance\n",
    "\n",
    "**Key Features**:\n",
    "- üîß Progressive resolution training (256‚Üí320‚Üí384px)\n",
    "- üß† 12-head transformer with 384-channel ASPP\n",
    "- üìä Multi-component boundary-aware loss\n",
    "- ‚ö° Mixed precision training with cosine scheduling\n",
    "- üéØ Real-time milestone tracking\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33797d4e",
   "metadata": {},
   "source": [
    "## üìã Section 1: Environment Setup & Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries and check environment\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üîç ENVIRONMENT VERIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check Python version\n",
    "print(f\"üêç Python Version: {sys.version.split()[0]}\")\n",
    "\n",
    "# Check PyTorch installation\n",
    "print(f\"üî• PyTorch Version: {torch.__version__}\")\n",
    "print(f\"üñ•Ô∏è  CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üéÆ GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "# Check current directory\n",
    "print(f\"üìÅ Current Directory: {os.getcwd()}\")\n",
    "print(f\"üìÖ Training Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\n‚úÖ Environment check complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a4589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to GhanaSegNet directory if needed\n",
    "try:\n",
    "    # Try to change to GhanaSegNet directory\n",
    "    if not os.getcwd().endswith('GhanaSegNet'):\n",
    "        if os.path.exists('GhanaSegNet'):\n",
    "            os.chdir('GhanaSegNet')\n",
    "            print(f\"üìÇ Changed to: {os.getcwd()}\")\n",
    "        elif os.path.exists('/content/GhanaSegNet'):\n",
    "            os.chdir('/content/GhanaSegNet')\n",
    "            print(f\"üìÇ Changed to: {os.getcwd()}\")\n",
    "    \n",
    "    # Verify essential files exist\n",
    "    essential_files = [\n",
    "        'scripts/train_baselines.py',\n",
    "        'models/ghanasegnet.py',\n",
    "        'utils/losses.py',\n",
    "        'utils/metrics.py'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüîç CHECKING ESSENTIAL FILES:\")\n",
    "    all_files_exist = True\n",
    "    for file_path in essential_files:\n",
    "        exists = os.path.exists(file_path)\n",
    "        status = \"‚úÖ\" if exists else \"‚ùå\"\n",
    "        print(f\"{status} {file_path}\")\n",
    "        if not exists:\n",
    "            all_files_exist = False\n",
    "    \n",
    "    if all_files_exist:\n",
    "        print(\"\\nüéâ All essential files found! Ready for training.\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Some files are missing. Please ensure you're in the correct directory.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Directory setup issue: {e}\")\n",
    "    print(\"Please ensure you're in the GhanaSegNet project directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a68a70",
   "metadata": {},
   "source": [
    "## üìä Section 2: Dataset Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset availability and structure\n",
    "print(\"üìä DATASET VERIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check for data directory\n",
    "data_paths_to_check = [\n",
    "    'data',\n",
    "    '/content/drive/MyDrive/GhanaFoodDataset',\n",
    "    '/content/GhanaFoodDataset',\n",
    "    '../data'\n",
    "]\n",
    "\n",
    "dataset_path = None\n",
    "for path in data_paths_to_check:\n",
    "    if os.path.exists(path):\n",
    "        dataset_path = path\n",
    "        print(f\"‚úÖ Found dataset at: {path}\")\n",
    "        break\n",
    "\n",
    "if dataset_path:\n",
    "    # Check dataset structure\n",
    "    required_dirs = ['train/images', 'train/masks', 'val/images', 'val/masks']\n",
    "    for dir_path in required_dirs:\n",
    "        full_path = os.path.join(dataset_path, dir_path)\n",
    "        if os.path.exists(full_path):\n",
    "            count = len([f for f in os.listdir(full_path) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "            print(f\"‚úÖ {dir_path}: {count} files\")\n",
    "        else:\n",
    "            print(f\"‚ùå Missing: {dir_path}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found! Please ensure dataset is available.\")\n",
    "    print(\"Expected locations:\")\n",
    "    for path in data_paths_to_check:\n",
    "        print(f\"   - {path}\")\n",
    "\n",
    "print(f\"\\nüéØ Dataset Path: {dataset_path if dataset_path else 'Not Found'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9746f2b",
   "metadata": {},
   "source": [
    "## üß† Section 3: Model Architecture Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model loading and verify enhanced architecture\n",
    "print(\"üß† MODEL ARCHITECTURE VERIFICATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Add project root to path\n",
    "    if '.' not in sys.path:\n",
    "        sys.path.append('.')\n",
    "    \n",
    "    # Import the enhanced model\n",
    "    from models.ghanasegnet import GhanaSegNet\n",
    "    \n",
    "    # Create model instance\n",
    "    model = GhanaSegNet(num_classes=6)\n",
    "    \n",
    "    # Calculate parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully!\")\n",
    "    print(f\"üìä Total Parameters: {total_params:,}\")\n",
    "    print(f\"üéØ Trainable Parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Expected enhanced model should have ~16M parameters\n",
    "    if total_params > 15_000_000:\n",
    "        print(f\"üöÄ Enhanced architecture detected! (16M+ parameters)\")\n",
    "        print(f\"   - 12-head transformer\")\n",
    "        print(f\"   - 384-channel ASPP\")\n",
    "        print(f\"   - Advanced spatial attention\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Standard architecture detected ({total_params/1e6:.1f}M parameters)\")\n",
    "    \n",
    "    # Test forward pass\n",
    "    dummy_input = torch.randn(1, 3, 256, 256)\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input)\n",
    "        if isinstance(output, tuple):\n",
    "            main_output, aux_output = output\n",
    "            print(f\"‚úÖ Multi-scale supervision active\")\n",
    "            print(f\"   Main output: {main_output.shape}\")\n",
    "            print(f\"   Auxiliary output: {aux_output.shape}\")\n",
    "        else:\n",
    "            print(f\"‚úÖ Forward pass successful: {output.shape}\")\n",
    "    \n",
    "    print(\"\\nüéâ Model verification complete!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Model loading failed: {e}\")\n",
    "    print(\"Please check that all model files are present and properly configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0ca4c",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Section 4: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training parameters for optimal 30% mIoU performance\n",
    "print(\"‚öôÔ∏è TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Training hyperparameters optimized for 30% mIoU target\n",
    "TRAINING_CONFIG = {\n",
    "    # Model settings\n",
    "    'model': 'ghanasegnet',\n",
    "    'num_classes': 6,\n",
    "    \n",
    "    # Training parameters (optimized for enhanced architecture)\n",
    "    'epochs': 15,\n",
    "    'batch_size': 6,  # Will adjust during progressive training\n",
    "    'learning_rate': 1.8e-4,  # Tuned for transformer components\n",
    "    'weight_decay': 1.5e-3,   # Enhanced regularization\n",
    "    \n",
    "    # Progressive training settings\n",
    "    'use_progressive_training': True,\n",
    "    'use_mixed_precision': True,\n",
    "    'use_cosine_schedule': True,\n",
    "    \n",
    "    # Environment settings\n",
    "    'device': 'auto',  # Will resolve to cuda/cpu\n",
    "    'dataset_path': dataset_path if 'dataset_path' in locals() else 'data',\n",
    "    'seed': 789,  # For reproducibility\n",
    "    \n",
    "    # Target settings\n",
    "    'target_miou': 30.0,\n",
    "    'early_stopping_patience': 6\n",
    "}\n",
    "\n",
    "print(\"üìã Training Configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "print(\"\\nüéØ PROGRESSIVE TRAINING SCHEDULE:\")\n",
    "print(\"   Epochs 1-5:   256x256 resolution, batch size 8\")\n",
    "print(\"   Epochs 6-11:  320x320 resolution, batch size 6\")\n",
    "print(\"   Epochs 12-15: 384x384 resolution, batch size 4\")\n",
    "\n",
    "print(\"\\nüöÄ ENHANCED FEATURES ACTIVE:\")\n",
    "print(\"   ‚úÖ 12-head transformer attention\")\n",
    "print(\"   ‚úÖ 384-channel ASPP module\")\n",
    "print(\"   ‚úÖ Multi-component loss (Dice+Boundary+Focal+CE)\")\n",
    "print(\"   ‚úÖ Mixed precision training\")\n",
    "print(\"   ‚úÖ Cosine annealing with warmup\")\n",
    "print(\"   ‚úÖ Early stopping protection\")\n",
    "\n",
    "print(\"\\n‚úÖ Configuration ready for 30% mIoU target!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0191b",
   "metadata": {},
   "source": [
    "## üöÄ Section 5: Execute Enhanced Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c3af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the enhanced GhanaSegNet training\n",
    "print(\"üöÄ STARTING ENHANCED GHANASEGNET TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üéØ TARGET: 30% mIoU\")\n",
    "print(f\"‚ö° STRATEGY: Progressive resolution + Enhanced architecture\")\n",
    "print(f\"üïê Start Time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Construct training command\n",
    "    cmd = [\n",
    "        'python', 'scripts/train_baselines.py',\n",
    "        '--model', TRAINING_CONFIG['model'],\n",
    "        '--epochs', str(TRAINING_CONFIG['epochs']),\n",
    "        '--batch-size', str(TRAINING_CONFIG['batch_size']),\n",
    "        '--lr', str(TRAINING_CONFIG['learning_rate']),\n",
    "        '--num-classes', str(TRAINING_CONFIG['num_classes']),\n",
    "        '--device', TRAINING_CONFIG['device'],\n",
    "        '--seed', str(TRAINING_CONFIG['seed'])\n",
    "    ]\n",
    "    \n",
    "    # Add dataset path if available\n",
    "    if TRAINING_CONFIG['dataset_path']:\n",
    "        cmd.extend(['--dataset-path', TRAINING_CONFIG['dataset_path']])\n",
    "    \n",
    "    print(f\"üîß Training Command: {' '.join(cmd)}\")\n",
    "    print(\"\\nüìä Training Progress:\")\n",
    "    \n",
    "    # Execute training with real-time output\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    \n",
    "    # Stream output in real-time\n",
    "    for line in iter(process.stdout.readline, ''):\n",
    "        print(line.rstrip())\n",
    "    \n",
    "    # Wait for completion\n",
    "    process.wait()\n",
    "    return_code = process.returncode\n",
    "    \n",
    "    print(f\"\\nüìä Training completed with return code: {return_code}\")\n",
    "    print(f\"üïê End Time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "    if return_code == 0:\n",
    "        print(\"\\nüéâ TRAINING SUCCESSFUL! üéâ\")\n",
    "        print(\"‚úÖ Check results in the next section\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå Training encountered issues\")\n",
    "        print(\"üîç Check error messages above\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Training execution failed: {e}\")\n",
    "    print(\"üîç Please check the error details above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42557d31",
   "metadata": {},
   "source": [
    "## üìà Section 6: Results Analysis & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze training results and check 30% mIoU achievement\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"üìà TRAINING RESULTS ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Load training results\n",
    "    results_file = 'checkpoints/ghanasegnet/ghanasegnet_results.json'\n",
    "    history_file = 'checkpoints/ghanasegnet/training_history.json'\n",
    "    \n",
    "    if os.path.exists(results_file):\n",
    "        with open(results_file, 'r') as f:\n",
    "            results = json.load(f)\n",
    "        \n",
    "        print(\"‚úÖ Training results loaded successfully!\")\n",
    "        print(\"\\nüéØ FINAL PERFORMANCE:\")\n",
    "        best_iou = results.get('best_iou', 0)\n",
    "        best_iou_percent = best_iou * 100\n",
    "        \n",
    "        print(f\"   Best mIoU: {best_iou:.4f} ({best_iou_percent:.2f}%)\")\n",
    "        print(f\"   Target:    0.3000 (30.00%)\")\n",
    "        print(f\"   Gap:       {30.0 - best_iou_percent:+.2f} percentage points\")\n",
    "        \n",
    "        # Achievement status\n",
    "        if best_iou >= 0.30:\n",
    "            print(\"\\nüèÜ TARGET ACHIEVED! 30%+ mIoU reached!\")\n",
    "        elif best_iou >= 0.28:\n",
    "            print(\"\\nüéâ EXCELLENT! Within 2% of target!\")\n",
    "        elif best_iou >= 0.27:\n",
    "            print(\"\\n‚úÖ GREAT! Solid improvement achieved!\")\n",
    "        elif best_iou >= 0.25:\n",
    "            print(\"\\nüìä GOOD! Meaningful progress made!\")\n",
    "        else:\n",
    "            print(\"\\nüìà Training completed - check for improvements\")\n",
    "        \n",
    "        print(f\"\\nüìä TRAINING STATISTICS:\")\n",
    "        print(f\"   Total Parameters: {results.get('total_parameters', 'N/A'):,}\")\n",
    "        print(f\"   Final Epoch: {results.get('final_epoch', 'N/A')}\")\n",
    "        print(f\"   Training Time: {results.get('timestamp', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"‚ùå Results file not found. Training may not have completed successfully.\")\n",
    "    \n",
    "    # Load and visualize training history\n",
    "    if os.path.exists(history_file):\n",
    "        with open(history_file, 'r') as f:\n",
    "            history = json.load(f)\n",
    "        \n",
    "        print(\"\\nüìä TRAINING HISTORY LOADED\")\n",
    "        \n",
    "        # Extract metrics\n",
    "        epochs = [h['epoch'] for h in history]\n",
    "        train_losses = [h['train_loss'] for h in history]\n",
    "        val_losses = [h['val_loss'] for h in history]\n",
    "        val_ious = [h['val_iou'] * 100 for h in history]  # Convert to percentage\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Training & Validation Loss\n",
    "        ax1.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "        ax1.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "        ax1.set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Validation IoU Progress\n",
    "        ax2.plot(epochs, val_ious, 'g-', linewidth=3, marker='o', markersize=4)\n",
    "        ax2.axhline(y=30.0, color='red', linestyle='--', linewidth=2, label='30% Target')\n",
    "        ax2.set_title('Validation mIoU Progress', fontsize=14, fontweight='bold')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('mIoU (%)')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_ylim(0, max(35, max(val_ious) + 2))\n",
    "        \n",
    "        # Learning Rate Schedule\n",
    "        if 'learning_rate' in history[0]:\n",
    "            lrs = [h['learning_rate'] for h in history]\n",
    "            ax3.plot(epochs, lrs, 'purple', linewidth=2)\n",
    "            ax3.set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "            ax3.set_xlabel('Epoch')\n",
    "            ax3.set_ylabel('Learning Rate')\n",
    "            ax3.set_yscale('log')\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Performance Summary\n",
    "        ax4.text(0.1, 0.8, f\"Best mIoU: {max(val_ious):.2f}%\", fontsize=16, fontweight='bold')\n",
    "        ax4.text(0.1, 0.7, f\"Target: 30.00%\", fontsize=14)\n",
    "        ax4.text(0.1, 0.6, f\"Gap: {30.0 - max(val_ious):+.2f}pp\", fontsize=14)\n",
    "        ax4.text(0.1, 0.5, f\"Final Epoch: {max(epochs)}\", fontsize=14)\n",
    "        \n",
    "        # Achievement status\n",
    "        if max(val_ious) >= 30.0:\n",
    "            status = \"üèÜ TARGET ACHIEVED!\"\n",
    "            color = 'green'\n",
    "        elif max(val_ious) >= 28.0:\n",
    "            status = \"üéâ EXCELLENT!\"\n",
    "            color = 'orange'\n",
    "        else:\n",
    "            status = \"üìä COMPLETED\"\n",
    "            color = 'blue'\n",
    "        \n",
    "        ax4.text(0.1, 0.3, status, fontsize=18, fontweight='bold', color=color)\n",
    "        ax4.set_xlim(0, 1)\n",
    "        ax4.set_ylim(0, 1)\n",
    "        ax4.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nüìà Training visualization complete!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Training history not found\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Results analysis failed: {e}\")\n",
    "    print(\"Please check if training completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abdfc75",
   "metadata": {},
   "source": [
    "## üíæ Section 7: Model Checkpoint Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c539bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about saved model checkpoints\n",
    "print(\"üíæ MODEL CHECKPOINT INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "checkpoint_dir = 'checkpoints/ghanasegnet'\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(f\"üìÅ Checkpoint Directory: {checkpoint_dir}\")\n",
    "    \n",
    "    # List all files in checkpoint directory\n",
    "    files = os.listdir(checkpoint_dir)\n",
    "    \n",
    "    print(\"\\nüìã Available Files:\")\n",
    "    for file in sorted(files):\n",
    "        file_path = os.path.join(checkpoint_dir, file)\n",
    "        file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB\n",
    "        print(f\"   ‚úÖ {file} ({file_size:.1f} MB)\")\n",
    "    \n",
    "    # Check for best model\n",
    "    best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
    "    if os.path.exists(best_model_path):\n",
    "        print(f\"\\nüèÜ BEST MODEL AVAILABLE:\")\n",
    "        print(f\"   Path: {best_model_path}\")\n",
    "        print(f\"   Size: {os.path.getsize(best_model_path) / (1024 * 1024):.1f} MB\")\n",
    "        \n",
    "        # Load checkpoint info\n",
    "        try:\n",
    "            checkpoint = torch.load(best_model_path, map_location='cpu')\n",
    "            print(f\"   Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "            print(f\"   Best IoU: {checkpoint.get('best_val_iou', 0):.4f}\")\n",
    "            print(f\"   Performance: {checkpoint.get('best_val_iou', 0) * 100:.2f}% mIoU\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è  Could not load checkpoint details: {e}\")\n",
    "    \n",
    "    print(\"\\nüîÑ TO RESUME TRAINING:\")\n",
    "    print(\"   Re-run the training cell with same configuration\")\n",
    "    \n",
    "    print(\"\\nüß™ TO USE FOR INFERENCE:\")\n",
    "    print(\"   Load best_model.pth for evaluation or deployment\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No checkpoints found. Training may not have started or completed.\")\n",
    "\n",
    "print(\"\\n‚úÖ Checkpoint information complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9a205",
   "metadata": {},
   "source": [
    "## üéØ Section 8: Quick Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a670a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick summary of training session\n",
    "print(\"üéØ ENHANCED GHANASEGNET TRAINING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Get final results\n",
    "    results_file = 'checkpoints/ghanasegnet/ghanasegnet_results.json'\n",
    "    if os.path.exists(results_file):\n",
    "        with open(results_file, 'r') as f:\n",
    "            results = json.load(f)\n",
    "        \n",
    "        best_iou = results.get('best_iou', 0)\n",
    "        best_iou_percent = best_iou * 100\n",
    "        \n",
    "        print(f\"üìä PERFORMANCE RESULTS:\")\n",
    "        print(f\"   üéØ Target mIoU:     30.00%\")\n",
    "        print(f\"   üèÜ Achieved mIoU:   {best_iou_percent:.2f}%\")\n",
    "        print(f\"   üìà Improvement:     {best_iou_percent - 24.37:+.2f}pp from baseline\")\n",
    "        \n",
    "        if best_iou >= 0.30:\n",
    "            print(f\"\\nüèÜ SUCCESS! TARGET ACHIEVED!\")\n",
    "            print(f\"   The enhanced GhanaSegNet reached 30%+ mIoU!\")\n",
    "        elif best_iou >= 0.27:\n",
    "            print(f\"\\nüéâ EXCELLENT PERFORMANCE!\")\n",
    "            print(f\"   Very close to 30% target with significant improvement!\")\n",
    "        else:\n",
    "            print(f\"\\nüìä TRAINING COMPLETED\")\n",
    "            print(f\"   Model shows improvement over baseline performance\")\n",
    "        \n",
    "        print(f\"\\nüîß ARCHITECTURE FEATURES USED:\")\n",
    "        print(f\"   ‚úÖ 12-head transformer attention\")\n",
    "        print(f\"   ‚úÖ 384-channel ASPP module\")\n",
    "        print(f\"   ‚úÖ Progressive training (256‚Üí320‚Üí384px)\")\n",
    "        print(f\"   ‚úÖ Multi-component boundary-aware loss\")\n",
    "        print(f\"   ‚úÖ Mixed precision training\")\n",
    "        print(f\"   ‚úÖ Cosine annealing with warmup\")\n",
    "        \n",
    "        print(f\"\\nüìã TECHNICAL DETAILS:\")\n",
    "        print(f\"   Parameters: {results.get('total_parameters', 'N/A'):,}\")\n",
    "        print(f\"   Epochs: {results.get('final_epoch', 'N/A')}\")\n",
    "        print(f\"   Training Method: Enhanced Progressive Training\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Training results not available\")\n",
    "        print(\"   Please check if training completed successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Summary generation failed: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üöÄ Enhanced GhanaSegNet Training Session Complete! üöÄ\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
