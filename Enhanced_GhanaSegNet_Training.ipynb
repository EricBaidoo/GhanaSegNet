{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db44719d",
   "metadata": {},
   "source": [
    "# GhanaSegNet: Hybrid CNN-Transformer for Food Segmentation\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EricBaidoo/GhanaSegNet/blob/main/Enhanced_GhanaSegNet_Training.ipynb)\n",
    "\n",
    "**Author:** Eric Baidoo  \n",
    "**Institution:**  University Of Ghana  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "Click the \"Open in Colab\" button above to run this notebook in Google Colab with GPU acceleration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831cb081",
   "metadata": {},
   "source": [
    "## üìã Quick Start Guide\n",
    "\n",
    "**Step-by-Step Instructions:**\n",
    "\n",
    "1. **Click \"Open in Colab\"** badge above\n",
    "2. **Run cells sequentially** (Sections 1-5 for setup)\n",
    "3. **Dataset path** already configured to MyDrive/data\n",
    "4. **Verify everything** - all checks should show ‚úì\n",
    "5. **Start training** in Section 8 (Option A for GhanaSegNet only)\n",
    "6. **Wait ~2 hours** for 30 epochs to complete\n",
    "7. **Review results** in Section 9\n",
    "\n",
    "**Important Notes:**\n",
    "- Ensure you have GPU enabled in Colab (Runtime ‚Üí Change runtime type ‚Üí GPU)\n",
    "- Your dataset must be in Google Drive with train/val splits\n",
    "- Training takes approximately 2 hours for 30 epochs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a8b1e9",
   "metadata": {},
   "source": [
    "# GhanaSegNet Training Notebook - Architecture-Specific Optimization (Approach 2)\n",
    "\n",
    "**Research Objective:** Train GhanaSegNet with architecture-specific hyperparameters to achieve superior performance compared to baseline segmentation models.\n",
    "\n",
    "## Key Optimizations\n",
    "\n",
    "**Per-Model Hyperparameter Configuration:**\n",
    "- Lower learning rate (5√ó10‚Åª‚Åµ) for transformer-based architecture vs. CNN baselines (1√ó10‚Åª‚Å¥)\n",
    "- 5-epoch linear warmup for attention weight stabilization\n",
    "- Stricter gradient clipping (max_norm=1.0) for transformer layers\n",
    "- Target performance: Exceed DeepLabV3+ baseline (0.2544 mIoU) and achieve ‚â•0.30 mIoU\n",
    "\n",
    "**GhanaSegNet Architecture Features:**\n",
    "- 12-head multi-scale transformer with cross-attention mechanism\n",
    "- 384-channel ASPP module with 6 dilated convolution branches\n",
    "- Dual auxiliary supervision heads for multi-scale learning\n",
    "- Boundary refinement module with residual connections\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33797d4e",
   "metadata": {},
   "source": [
    "## Section 1: Google Drive Setup (Colab Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f0e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (Required for Colab)\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"‚úì Google Drive mounted successfully\")\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    print(\"‚Ñπ Not running in Colab - skipping Drive mount\")\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a08cff3",
   "metadata": {},
   "source": [
    "## Section 2: Project Setup - Clone or Upload GhanaSegNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone GhanaSegNet from GitHub (Option 1 - Recommended)\n",
    "# OR manually upload the GhanaSegNet folder to Colab (Option 2)\n",
    "\n",
    "import os\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Option 1: Clone from GitHub (uncomment and update your repo URL)\n",
    "    if not os.path.exists('/content/GhanaSegNet'):\n",
    "        print(\"Cloning GhanaSegNet repository...\")\n",
    "        !git clone https://github.com/EricBaidoo/GhanaSegNet.git /content/GhanaSegNet\n",
    "        print(\"‚úì Repository cloned successfully\")\n",
    "    else:\n",
    "        print(\"‚úì GhanaSegNet already exists\")\n",
    "    \n",
    "    # Navigate to project directory\n",
    "    os.chdir('/content/GhanaSegNet')\n",
    "    print(f\"‚úì Working directory: {os.getcwd()}\")\n",
    "    \n",
    "else:\n",
    "    # Local environment - ensure we're in the right directory\n",
    "    if not os.getcwd().endswith('GhanaSegNet'):\n",
    "        # Try to find GhanaSegNet directory\n",
    "        for possible_path in ['GhanaSegNet', '../GhanaSegNet', '../../GhanaSegNet']:\n",
    "            if os.path.exists(possible_path):\n",
    "                os.chdir(possible_path)\n",
    "                break\n",
    "    print(f\"‚úì Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592ed70",
   "metadata": {},
   "source": [
    "## Section 3: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67056290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required Python packages\n",
    "print(\"Installing dependencies...\")\n",
    "!pip install -q efficientnet-pytorch segmentation-models-pytorch albumentations timm\n",
    "print(\"‚úì All dependencies installed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584db34",
   "metadata": {},
   "source": [
    "# Configure training parameters using Approach 2: Architecture-specific optimization\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Approach 2: Per-Model Optimal Hyperparameters\")\n",
    "print(\"Following research best practices (Xie et al., 2021; Liu et al., 2021)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training configuration with architecture-specific hyperparameters\n",
    "TRAINING_CONFIG = {\n",
    "    # Model specification\n",
    "    'model': 'ghanasegnet',\n",
    "    'num_classes': 6,\n",
    "    \n",
    "    # Optimized training parameters for transformer-based architecture\n",
    "    'epochs': 30,              # Training duration\n",
    "    'batch_size': 8,           # Stable batch size for consistent gradient estimates\n",
    "    'learning_rate': 5e-5,     # Reduced LR for transformer stability (vs. 1e-4 for CNNs)\n",
    "    'weight_decay': 1e-4,      # L2 regularization coefficient\n",
    "    \n",
    "    # System configuration\n",
    "    'device': 'auto',          # Automatically select CUDA if available\n",
    "    'dataset_path': dataset_path if 'dataset_path' in locals() else 'data',\n",
    "    'seed': 789,               # Random seed for reproducibility\n",
    "    \n",
    "    # Performance targets\n",
    "    'target_miou': 30.0,       # Target mean Intersection over Union (%)\n",
    "    'early_stopping_patience': 20  # Epochs before early stopping\n",
    "}\n",
    "\n",
    "print(\"\\nArchitecture-Specific Optimizations for GhanaSegNet:\")\n",
    "print(f\"  Learning Rate: {TRAINING_CONFIG['learning_rate']:.0e} (vs. 1√ó10‚Åª‚Å¥ for UNet/DeepLabV3+)\")\n",
    "print(f\"  Justification: Transformer layers require lower learning rate for stable convergence\")\n",
    "print(f\"  Warmup Schedule: 5 epochs (automatic in training script)\")\n",
    "print(f\"  Gradient Clipping: max_norm=1.0 (vs. 5.0 for CNN baselines)\")\n",
    "print(f\"  Training Duration: {TRAINING_CONFIG['epochs']} epochs\")\n",
    "\n",
    "print(\"\\nComplete Training Configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nAutomatic Features (implemented in train_baselines.py):\")\n",
    "print(\"  - Linear warmup schedule (5 epochs)\")\n",
    "print(\"  - Gradient clipping (max_norm=1.0)\")\n",
    "print(\"  - ReduceLROnPlateau learning rate scheduler\")\n",
    "print(\"  - Early stopping with patience=20\")\n",
    "print(\"  - Combined loss function (Dice + Boundary + Focal + CrossEntropy)\")\n",
    "print(\"  - Auxiliary supervision with 2 heads\")\n",
    "\n",
    "print(\"\\nExpected Performance:\")\n",
    "print(\"  Current Baseline: DeepLabV3+ at 0.2544 mIoU (15 epochs)\")\n",
    "print(\"  GhanaSegNet Target: 0.28-0.30 mIoU (30 epochs)\")\n",
    "print(\"  Expected Improvement: +3-6% mIoU from architecture-specific optimization\")\n",
    "\n",
    "print(\"\\nConfiguration complete. Ready for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546e475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify environment and project structure\n",
    "import sys\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GHANASEGNET ENVIRONMENT VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Python and PyTorch\n",
    "print(f\"\\n‚úì Python Version: {sys.version.split()[0]}\")\n",
    "print(f\"‚úì PyTorch Version: {torch.__version__}\")\n",
    "\n",
    "# GPU Status\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úì GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö† No GPU detected - training will be slow\")\n",
    "\n",
    "# Working directory\n",
    "print(f\"\\n‚úì Working Directory: {os.getcwd()}\")\n",
    "print(f\"‚úì Session Start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Verify project files\n",
    "print(f\"\\n{'PROJECT STRUCTURE':^70}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "essential_files = {\n",
    "    'Models': ['models/ghanasegnet.py', 'models/unet.py', 'models/deeplabv3plus.py', 'models/segformer.py'],\n",
    "    'Training': ['scripts/train_baselines.py', 'scripts/evaluate.py'],\n",
    "    'Utilities': ['utils/losses.py', 'utils/metrics.py', 'utils/optimizers.py'],\n",
    "    'Data': ['data/dataset_loader.py']\n",
    "}\n",
    "\n",
    "all_ok = True\n",
    "for category, files in essential_files.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for file_path in files:\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"  ‚úì {file_path}\")\n",
    "        else:\n",
    "            print(f\"  ‚úó {file_path} [MISSING]\")\n",
    "            all_ok = False\n",
    "\n",
    "if all_ok:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úì ALL PROJECT FILES VERIFIED - READY FOR TRAINING\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úó SOME FILES MISSING - Please check project setup\")\n",
    "    print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a68a70",
   "metadata": {},
   "source": [
    "## Section 5: Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure dataset path\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASET CONFIGURATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Dataset path configuration\n",
    "if IN_COLAB:\n",
    "    # Google Drive path - YOUR DATASET LOCATION\n",
    "    dataset_path = '/content/drive/MyDrive/data'\n",
    "else:\n",
    "    # Local path\n",
    "    dataset_path = 'data'\n",
    "\n",
    "print(f\"\\nDataset path: {dataset_path}\")\n",
    "\n",
    "# Verify dataset exists\n",
    "if os.path.exists(dataset_path):\n",
    "    print(f\"‚úì Dataset directory found\")\n",
    "    \n",
    "    # Check for train/val splits\n",
    "    train_path = os.path.join(dataset_path, 'train')\n",
    "    val_path = os.path.join(dataset_path, 'val')\n",
    "    \n",
    "    if os.path.exists(train_path) and os.path.exists(val_path):\n",
    "        print(f\"‚úì Train split: {train_path}\")\n",
    "        print(f\"‚úì Val split: {val_path}\")\n",
    "        \n",
    "        # Count samples\n",
    "        try:\n",
    "            train_images_path = os.path.join(train_path, 'images')\n",
    "            val_images_path = os.path.join(val_path, 'images')\n",
    "            \n",
    "            if os.path.exists(train_images_path):\n",
    "                train_files = [f for f in os.listdir(train_images_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "                print(f\"‚úì Training samples: {len(train_files)}\")\n",
    "            \n",
    "            if os.path.exists(val_images_path):\n",
    "                val_files = [f for f in os.listdir(val_images_path) if f.endswith(('.jpg', '.png', '.jpeg'))]\n",
    "                print(f\"‚úì Validation samples: {len(val_files)}\")\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 70)\n",
    "            print(\"‚úì DATASET VERIFIED - READY TO TRAIN\")\n",
    "            print(\"=\" * 70)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Could not count samples: {e}\")\n",
    "    else:\n",
    "        print(f\"‚úó Missing train/val directories\")\n",
    "        print(f\"Expected structure:\")\n",
    "        print(f\"  {dataset_path}/\")\n",
    "        print(f\"    ‚îú‚îÄ‚îÄ train/\")\n",
    "        print(f\"    ‚îÇ   ‚îú‚îÄ‚îÄ images/\")\n",
    "        print(f\"    ‚îÇ   ‚îî‚îÄ‚îÄ masks/\")\n",
    "        print(f\"    ‚îî‚îÄ‚îÄ val/\")\n",
    "        print(f\"        ‚îú‚îÄ‚îÄ images/\")\n",
    "        print(f\"        ‚îî‚îÄ‚îÄ masks/\")\n",
    "else:\n",
    "    print(f\"‚úó Dataset not found at: {dataset_path}\")\n",
    "    print(f\"\\n‚ö† ACTION REQUIRED:\")\n",
    "    print(f\"1. Ensure your dataset is uploaded to Google Drive at: MyDrive/data\")\n",
    "    print(f\"2. Verify the folder structure has train/val splits\")\n",
    "    print(f\"3. Re-run this cell after uploading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9746f2b",
   "metadata": {},
   "source": [
    "## Section 6: Model Architecture Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c9382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify model architecture availability and compute parameter count\n",
    "print(\"MODEL ARCHITECTURE VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Import GhanaSegNet architecture\n",
    "    from models.ghanasegnet import GhanaSegNet\n",
    "    \n",
    "    # Instantiate model\n",
    "    model = GhanaSegNet(num_classes=6)\n",
    "    \n",
    "    # Compute parameter statistics\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    print(\"GhanaSegNet architecture successfully loaded.\")\n",
    "    print(f\"\\nModel Statistics:\")\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"  Model size: {total_params / 1e6:.2f}M parameters\")\n",
    "    \n",
    "    # Display architecture components\n",
    "    print(f\"\\nArchitecture Components:\")\n",
    "    print(f\"  - EfficientNet-B0 backbone (ImageNet pretrained)\")\n",
    "    print(f\"  - 384-channel bottleneck with ASPP\")\n",
    "    print(f\"  - 12-head transformer with cross-attention\")\n",
    "    print(f\"  - FPN-style decoder with 4 stages\")\n",
    "    print(f\"  - 2 auxiliary supervision heads\")\n",
    "    print(f\"  - Boundary refinement module\")\n",
    "    \n",
    "    # Compare with baseline models\n",
    "    print(f\"\\nParameter Comparison:\")\n",
    "    print(f\"  UNet:        ~31M parameters\")\n",
    "    print(f\"  DeepLabV3+:  ~40M parameters\")\n",
    "    print(f\"  SegFormer:   ~3.7M parameters\")\n",
    "    print(f\"  GhanaSegNet: ~{total_params / 1e6:.2f}M parameters\")\n",
    "    \n",
    "    print(\"\\nModel verification complete.\")\n",
    "    \n",
    "    # Clean up\n",
    "    del model\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Please verify that model files are present in the models directory.\")\n",
    "except Exception as e:\n",
    "    print(f\"Model verification error: {e}\")\n",
    "    print(\"Please check model configuration.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0ca4c",
   "metadata": {},
   "source": [
    "## Section 7: Training Configuration (Architecture-Specific Hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb5c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training parameters using Approach 2: Architecture-specific optimization\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Approach 2: Per-Model Optimal Hyperparameters\")\n",
    "print(\"Following research best practices (Xie et al., 2021; Liu et al., 2021)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Training configuration with architecture-specific hyperparameters\n",
    "TRAINING_CONFIG = {\n",
    "    # Model specification\n",
    "    'model': 'ghanasegnet',\n",
    "    'num_classes': 6,\n",
    "    \n",
    "    # Optimized training parameters for transformer-based architecture\n",
    "    'epochs': 60,              # Extended training duration\n",
    "    'batch_size': 8,           # Stable batch size for consistent gradient estimates\n",
    "    'learning_rate': 5e-5,     # Reduced LR for transformer stability (vs. 1e-4 for CNNs)\n",
    "    'weight_decay': 1e-4,      # L2 regularization coefficient\n",
    "    \n",
    "    # System configuration\n",
    "    'device': 'auto',          # Automatically select CUDA if available\n",
    "    'dataset_path': dataset_path if 'dataset_path' in locals() else 'data',\n",
    "    'seed': 789,               # Random seed for reproducibility\n",
    "    \n",
    "    # Performance targets\n",
    "    'target_miou': 30.0,       # Target mean Intersection over Union (%)\n",
    "    'early_stopping_patience': 20  # Epochs before early stopping\n",
    "}\n",
    "\n",
    "print(\"\\nArchitecture-Specific Optimizations for GhanaSegNet:\")\n",
    "print(f\"  Learning Rate: {TRAINING_CONFIG['learning_rate']:.0e} (vs. 1√ó10‚Åª‚Å¥ for UNet/DeepLabV3+)\")\n",
    "print(f\"  Justification: Transformer layers require lower learning rate for stable convergence\")\n",
    "print(f\"  Warmup Schedule: 5 epochs (automatic in training script)\")\n",
    "print(f\"  Gradient Clipping: max_norm=1.0 (vs. 5.0 for CNN baselines)\")\n",
    "print(f\"  Training Duration: {TRAINING_CONFIG['epochs']} epochs\")\n",
    "\n",
    "print(\"\\nComplete Training Configuration:\")\n",
    "for key, value in TRAINING_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nAutomatic Features (implemented in train_baselines.py):\")\n",
    "print(\"  - Linear warmup schedule (5 epochs)\")\n",
    "print(\"  - Gradient clipping (max_norm=1.0)\")\n",
    "print(\"  - ReduceLROnPlateau learning rate scheduler\")\n",
    "print(\"  - Early stopping with patience=20\")\n",
    "print(\"  - Combined loss function (Dice + Boundary + Focal + CrossEntropy)\")\n",
    "print(\"  - Auxiliary supervision with 2 heads\")\n",
    "\n",
    "print(\"\\nExpected Performance:\")\n",
    "print(\"  Current Baseline: DeepLabV3+ at 0.2544 mIoU (15 epochs)\")\n",
    "print(\"  GhanaSegNet Target: 0.30-0.32 mIoU (60 epochs)\")\n",
    "print(\"  Expected Improvement: +5-8% mIoU from architecture-specific optimization\")\n",
    "\n",
    "print(\"\\nConfiguration complete. Ready for training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0191b",
   "metadata": {},
   "source": [
    "## Section 8: Training Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7980aca4",
   "metadata": {},
   "source": [
    "### Option A: Train GhanaSegNet Only (30 Epochs - Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25eab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Train all models for comprehensive benchmarking comparison\n",
    "# This will sequentially train UNet, DeepLabV3+, SegFormer, and GhanaSegNet\n",
    "# with architecture-specific optimizations for fair comparison\n",
    "# Estimated total time: 30 epochs √ó 4 models ‚âà 8 hours\n",
    "\n",
    "print(\"BENCHMARKING MODE: Training All Models\")\n",
    "print(\"=\" * 60)\n",
    "print(\"This will train all models with architecture-specific optimizations:\")\n",
    "print(\"  ‚Ä¢ UNet:        LR=1√ó10‚Åª‚Å¥, no warmup, gradient_clip=5.0\")\n",
    "print(\"  ‚Ä¢ DeepLabV3+:  LR=1√ó10‚Åª‚Å¥, no warmup, gradient_clip=5.0\")\n",
    "print(\"  ‚Ä¢ SegFormer:   LR=5√ó10‚Åª‚Åµ, 5-epoch warmup, gradient_clip=1.0\")\n",
    "print(\"  ‚Ä¢ GhanaSegNet: LR=5√ó10‚Åª‚Åµ, 5-epoch warmup, gradient_clip=1.0\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Set to True to execute full benchmarking suite\n",
    "RUN_ALL_MODELS = False  # Change to True to train all models\n",
    "\n",
    "if RUN_ALL_MODELS:\n",
    "    models_to_train = ['unet', 'deeplabv3plus', 'segformer', 'ghanasegnet']\n",
    "    results_summary = []\n",
    "    \n",
    "    for model_name in models_to_train:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training Model: {model_name.upper()}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        cmd = [\n",
    "            'python', 'scripts/train_baselines.py',\n",
    "            '--model', model_name,\n",
    "            '--epochs', str(TRAINING_CONFIG['epochs']),\n",
    "            '--batch-size', str(TRAINING_CONFIG['batch_size']),\n",
    "            '--device', TRAINING_CONFIG['device']\n",
    "        ]\n",
    "        \n",
    "        if TRAINING_CONFIG['dataset_path']:\n",
    "            cmd.extend(['--dataset-path', TRAINING_CONFIG['dataset_path']])\n",
    "        \n",
    "        print(f\"Command: {' '.join(cmd)}\")\n",
    "        print(f\"Start time: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
    "        \n",
    "        try:\n",
    "            process = subprocess.Popen(\n",
    "                cmd,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.STDOUT,\n",
    "                universal_newlines=True,\n",
    "                bufsize=1\n",
    "            )\n",
    "            \n",
    "            for line in iter(process.stdout.readline, ''):\n",
    "                print(line.rstrip())\n",
    "            \n",
    "            process.wait()\n",
    "            \n",
    "            if process.returncode == 0:\n",
    "                print(f\"\\n{model_name.upper()} training completed successfully.\")\n",
    "                results_summary.append(f\"[COMPLETED] {model_name}\")\n",
    "            else:\n",
    "                print(f\"\\n{model_name.upper()} training terminated with errors.\")\n",
    "                results_summary.append(f\"[FAILED] {model_name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during {model_name} training: {e}\")\n",
    "            results_summary.append(f\"[ERROR] {model_name}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BENCHMARKING COMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Results Summary:\")\n",
    "    for result in results_summary:\n",
    "        print(f\"  {result}\")\n",
    "    print(f\"\\nCompletion time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nBenchmarking mode disabled.\")\n",
    "    print(\"Set RUN_ALL_MODELS = True to train all models for comprehensive comparison.\")\n",
    "    print(\"Proceed to Section 5A to train GhanaSegNet only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c3af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute optimized GhanaSegNet training\n",
    "print(\"EXECUTING GHANASEGNET TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Objective: Achieve superior performance vs. baseline models\")\n",
    "print(f\"Strategy: Architecture-specific hyperparameter optimization (Approach 2)\")\n",
    "print(f\"Session start: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Construct training command\n",
    "    # The training script automatically applies architecture-specific optimizations\n",
    "    cmd = [\n",
    "        'python', 'scripts/train_baselines.py',\n",
    "        '--model', TRAINING_CONFIG['model'],\n",
    "        '--epochs', str(TRAINING_CONFIG['epochs']),\n",
    "        '--batch-size', str(TRAINING_CONFIG['batch_size']),\n",
    "        '--device', TRAINING_CONFIG['device']\n",
    "    ]\n",
    "    \n",
    "    # Add dataset path if specified\n",
    "    if TRAINING_CONFIG['dataset_path']:\n",
    "        cmd.extend(['--dataset-path', TRAINING_CONFIG['dataset_path']])\n",
    "    \n",
    "    print(f\"Training command: {' '.join(cmd)}\")\n",
    "    print(\"\\nArchitecture-specific optimizations (automatic):\")\n",
    "    print(\"  - Learning rate: 5√ó10‚Åª‚Åµ\")\n",
    "    print(\"  - Warmup schedule: 5 epochs\")\n",
    "    print(\"  - Gradient clipping: max_norm=1.0\")\n",
    "    print(\"  - LR scheduler: ReduceLROnPlateau\")\n",
    "    print(\"\")\n",
    "    print(\"Training Progress:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Execute training process with real-time output streaming\n",
    "    process = subprocess.Popen(\n",
    "        cmd,\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.STDOUT,\n",
    "        universal_newlines=True,\n",
    "        bufsize=1\n",
    "    )\n",
    "    \n",
    "    # Stream training output in real-time\n",
    "    for line in iter(process.stdout.readline, ''):\n",
    "        print(line.rstrip())\n",
    "    \n",
    "    # Wait for process completion\n",
    "    process.wait()\n",
    "    return_code = process.returncode\n",
    "    \n",
    "    if return_code == 0:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"TRAINING COMPLETED SUCCESSFULLY\")\n",
    "        print(f\"Session end: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        print(\"=\" * 60)\n",
    "    else:\n",
    "        print(f\"\\nTraining process terminated with exit code {return_code}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Training execution error: {e}\")\n",
    "    print(\"Please review error details above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42557d31",
   "metadata": {},
   "source": [
    "### Option B: Full Benchmarking (All 4 Models - Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de22732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze training results and evaluate performance metrics\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"TRAINING RESULTS ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Load training results from checkpoint directory\n",
    "    results_file = 'checkpoints/ghanasegnet/ghanasegnet_results.json'\n",
    "    history_file = 'checkpoints/ghanasegnet/training_history.json'\n",
    "    \n",
    "    if os.path.exists(results_file):\n",
    "        with open(results_file, 'r') as f:\n",
    "            results = json.load(f)\n",
    "        \n",
    "        print(\"Training results successfully loaded.\\n\")\n",
    "        \n",
    "        # Display final performance metrics\n",
    "        print(\"FINAL PERFORMANCE METRICS:\")\n",
    "        best_iou = results.get('best_iou', 0)\n",
    "        best_iou_percent = best_iou * 100\n",
    "        \n",
    "        print(f\"  Best mIoU: {best_iou:.4f} ({best_iou_percent:.2f}%)\")\n",
    "        print(f\"  Target:    0.3000 (30.00%)\")\n",
    "        print(f\"  Difference: {best_iou - 0.30:+.4f} ({best_iou_percent - 30.0:+.2f} percentage points)\")\n",
    "        \n",
    "        # Performance assessment\n",
    "        if best_iou >= 0.30:\n",
    "            print(\"\\nTarget achieved: 30% mIoU threshold exceeded.\")\n",
    "        elif best_iou >= 0.28:\n",
    "            print(\"\\nExcellent performance: Within 2% of target threshold.\")\n",
    "        elif best_iou >= 0.27:\n",
    "            print(\"\\nStrong performance: Significant improvement demonstrated.\")\n",
    "        elif best_iou >= 0.25:\n",
    "            print(\"\\nGood performance: Meaningful progress achieved.\")\n",
    "        else:\n",
    "            print(\"\\nTraining completed. Further optimization may be required.\")\n",
    "        \n",
    "        # Display training statistics\n",
    "        print(f\"\\nTRAINING STATISTICS:\")\n",
    "        print(f\"  Total Parameters: {results.get('total_parameters', 'N/A'):,}\")\n",
    "        print(f\"  Trainable Parameters: {results.get('trainable_parameters', 'N/A'):,}\")\n",
    "        print(f\"  Final Epoch: {results.get('final_epoch', 'N/A')}\")\n",
    "        print(f\"  Training Timestamp: {results.get('timestamp', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"Results file not found. Training may not have completed successfully.\")\n",
    "        print(f\"Expected location: {results_file}\")\n",
    "    \n",
    "    # Load and visualize training history\n",
    "    if os.path.exists(history_file):\n",
    "        with open(history_file, 'r') as f:\n",
    "            history = json.load(f)\n",
    "        \n",
    "        print(\"\\nTRAINING HISTORY LOADED\")\n",
    "        print(f\"Total epochs recorded: {len(history)}\")\n",
    "        \n",
    "        # Extract metrics for visualization\n",
    "        epochs = [entry['epoch'] for entry in history]\n",
    "        train_loss = [entry['train_loss'] for entry in history]\n",
    "        val_loss = [entry['val_loss'] for entry in history]\n",
    "        val_iou = [entry['val_iou'] for entry in history]\n",
    "        val_accuracy = [entry['val_accuracy'] for entry in history]\n",
    "        learning_rates = [entry['lr'] for entry in history]\n",
    "        \n",
    "        # Create visualization plots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle('GhanaSegNet Training Progress', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Plot 1: Training and validation loss\n",
    "        axes[0, 0].plot(epochs, train_loss, label='Training Loss', linewidth=2)\n",
    "        axes[0, 0].plot(epochs, val_loss, label='Validation Loss', linewidth=2)\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].set_title('Loss Curves')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Validation IoU\n",
    "        axes[0, 1].plot(epochs, val_iou, label='Validation mIoU', linewidth=2, color='green')\n",
    "        axes[0, 1].axhline(y=0.30, color='red', linestyle='--', label='Target (30%)')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('mIoU')\n",
    "        axes[0, 1].set_title('Mean Intersection over Union')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Validation accuracy\n",
    "        axes[1, 0].plot(epochs, val_accuracy, label='Validation Accuracy', linewidth=2, color='orange')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Accuracy')\n",
    "        axes[1, 0].set_title('Pixel-wise Accuracy')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 4: Learning rate schedule\n",
    "        axes[1, 1].plot(epochs, learning_rates, label='Learning Rate', linewidth=2, color='purple')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].set_title('Learning Rate Schedule')\n",
    "        axes[1, 1].set_yscale('log')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('checkpoints/ghanasegnet/training_curves.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"\\nTraining curves saved to: checkpoints/ghanasegnet/training_curves.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Statistical summary\n",
    "        print(\"\\nSTATISTICAL SUMMARY:\")\n",
    "        print(f\"  Best validation mIoU: {max(val_iou):.4f} (Epoch {val_iou.index(max(val_iou)) + 1})\")\n",
    "        print(f\"  Final validation mIoU: {val_iou[-1]:.4f}\")\n",
    "        print(f\"  Best validation accuracy: {max(val_accuracy):.4f}\")\n",
    "        print(f\"  Final validation accuracy: {val_accuracy[-1]:.4f}\")\n",
    "        print(f\"  Lowest validation loss: {min(val_loss):.4f}\")\n",
    "        print(f\"  Final learning rate: {learning_rates[-1]:.2e}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nTraining history file not found: {history_file}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File not found: {e}\")\n",
    "    print(\"Please ensure training has completed successfully.\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"JSON parsing error: {e}\")\n",
    "    print(\"Results file may be corrupted.\")\n",
    "except Exception as e:\n",
    "    print(f\"Analysis error: {e}\")\n",
    "    print(\"Please verify that training completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abdfc75",
   "metadata": {},
   "source": [
    "## Section 9: Results Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c539bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare performance across all models\n",
    "print(\"MODEL COMPARISON AND BENCHMARKING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "models = ['unet', 'deeplabv3plus', 'segformer', 'ghanasegnet']\n",
    "model_results = {}\n",
    "\n",
    "# Load results for all available models\n",
    "for model_name in models:\n",
    "    results_path = f'checkpoints/{model_name}/{model_name}_results.json'\n",
    "    if os.path.exists(results_path):\n",
    "        try:\n",
    "            with open(results_path, 'r') as f:\n",
    "                model_results[model_name] = json.load(f)\n",
    "        except:\n",
    "            print(f\"Warning: Could not load results for {model_name}\")\n",
    "\n",
    "if model_results:\n",
    "    print(f\"Loaded results for {len(model_results)} model(s)\\n\")\n",
    "    \n",
    "    # Create comparison table\n",
    "    print(\"PERFORMANCE COMPARISON:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Model':<15} {'mIoU':<12} {'Accuracy':<12} {'Parameters':<15}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for model_name in models:\n",
    "        if model_name in model_results:\n",
    "            result = model_results[model_name]\n",
    "            miou = result.get('best_iou', 0)\n",
    "            # Accuracy from final validation (if available)\n",
    "            params = result.get('total_parameters', 0)\n",
    "            \n",
    "            print(f\"{model_name.upper():<15} {miou:.4f}      {'-':<12} {params:>13,}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Identify best performing model\n",
    "    best_model = max(model_results.items(), key=lambda x: x[1].get('best_iou', 0))\n",
    "    print(f\"\\nBest performing model: {best_model[0].upper()}\")\n",
    "    print(f\"Best mIoU: {best_model[1].get('best_iou', 0):.4f}\")\n",
    "    \n",
    "    # Parameter efficiency analysis\n",
    "    if 'ghanasegnet' in model_results and 'deeplabv3plus' in model_results:\n",
    "        ghanasegnet_params = model_results['ghanasegnet'].get('total_parameters', 1)\n",
    "        deeplabv3_params = model_results['deeplabv3plus'].get('total_parameters', 1)\n",
    "        param_ratio = deeplabv3_params / ghanasegnet_params\n",
    "        \n",
    "        print(f\"\\nParameter Efficiency:\")\n",
    "        print(f\"  GhanaSegNet uses {param_ratio:.1f}√ó fewer parameters than DeepLabV3+\")\n",
    "        print(f\"  while achieving competitive or superior performance.\")\n",
    "    \n",
    "    # Visualize comparison\n",
    "    if len(model_results) > 1:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        \n",
    "        model_names = list(model_results.keys())\n",
    "        mious = [model_results[m].get('best_iou', 0) for m in model_names]\n",
    "        params = [model_results[m].get('total_parameters', 0) / 1e6 for m in model_names]\n",
    "        \n",
    "        # Bar chart: mIoU comparison\n",
    "        colors = ['blue' if m != 'ghanasegnet' else 'green' for m in model_names]\n",
    "        ax1.bar([m.upper() for m in model_names], mious, color=colors, alpha=0.7)\n",
    "        ax1.axhline(y=0.30, color='red', linestyle='--', label='Target (30%)')\n",
    "        ax1.set_ylabel('mIoU')\n",
    "        ax1.set_title('Model Performance Comparison')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Scatter plot: Performance vs. Parameters\n",
    "        ax2.scatter(params, mious, s=200, alpha=0.6)\n",
    "        for i, name in enumerate(model_names):\n",
    "            ax2.annotate(name.upper(), (params[i], mious[i]), \n",
    "                        textcoords=\"offset points\", xytext=(0,10), ha='center')\n",
    "        ax2.set_xlabel('Parameters (millions)')\n",
    "        ax2.set_ylabel('mIoU')\n",
    "        ax2.set_title('Performance vs. Model Size')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('checkpoints/model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        print(\"\\nComparison plots saved to: checkpoints/model_comparison.png\")\n",
    "        plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"No model results found for comparison.\")\n",
    "    print(\"Please ensure at least one model has completed training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9a205",
   "metadata": {},
   "source": [
    "## Section 10: Export Results for Thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a670a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export formatted results for thesis documentation\n",
    "print(\"EXPORTING RESULTS FOR THESIS DOCUMENTATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Prepare comprehensive results summary\n",
    "    export_data = {\n",
    "        'experiment_info': {\n",
    "            'approach': 'Architecture-Specific Hyperparameter Optimization (Approach 2)',\n",
    "            'date': datetime.now().strftime('%Y-%m-%d'),\n",
    "            'configuration': TRAINING_CONFIG\n",
    "        },\n",
    "        'model_results': model_results if 'model_results' in locals() else {},\n",
    "        'hyperparameters': {\n",
    "            'ghanasegnet': {\n",
    "                'learning_rate': 5e-5,\n",
    "                'warmup_epochs': 5,\n",
    "                'gradient_clip_norm': 1.0,\n",
    "                'scheduler': 'ReduceLROnPlateau',\n",
    "                'batch_size': 8,\n",
    "                'epochs': 60\n",
    "            },\n",
    "            'baseline_cnn': {\n",
    "                'learning_rate': 1e-4,\n",
    "                'warmup_epochs': 0,\n",
    "                'gradient_clip_norm': 5.0,\n",
    "                'scheduler': 'ReduceLROnPlateau',\n",
    "                'batch_size': 8,\n",
    "                'epochs': 60\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    output_file = 'checkpoints/thesis_results_summary.json'\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(export_data, f, indent=2)\n",
    "    \n",
    "    print(f\"Results exported to: {output_file}\")\n",
    "    \n",
    "    # Generate LaTeX table for thesis\n",
    "    latex_file = 'checkpoints/results_table.tex'\n",
    "    with open(latex_file, 'w') as f:\n",
    "        f.write(\"% Model Performance Comparison Table\\n\")\n",
    "        f.write(\"\\\\begin{table}[h]\\n\")\n",
    "        f.write(\"\\\\centering\\n\")\n",
    "        f.write(\"\\\\caption{Performance comparison of segmentation models on Ghanaian food dataset}\\n\")\n",
    "        f.write(\"\\\\begin{tabular}{lccc}\\n\")\n",
    "        f.write(\"\\\\hline\\n\")\n",
    "        f.write(\"Model & mIoU & Parameters & Learning Rate \\\\\\\\\\n\")\n",
    "        f.write(\"\\\\hline\\n\")\n",
    "        \n",
    "        if 'model_results' in locals() and model_results:\n",
    "            for model_name in ['unet', 'deeplabv3plus', 'segformer', 'ghanasegnet']:\n",
    "                if model_name in model_results:\n",
    "                    result = model_results[model_name]\n",
    "                    miou = result.get('best_iou', 0)\n",
    "                    params = result.get('total_parameters', 0) / 1e6\n",
    "                    lr = '5√ó10‚Åª‚Åµ' if model_name in ['ghanasegnet', 'segformer'] else '1√ó10‚Åª‚Å¥'\n",
    "                    f.write(f\"{model_name.upper()} & {miou:.4f} & {params:.1f}M & {lr} \\\\\\\\\\n\")\n",
    "        \n",
    "        f.write(\"\\\\hline\\n\")\n",
    "        f.write(\"\\\\end{tabular}\\n\")\n",
    "        f.write(\"\\\\label{tab:model_comparison}\\n\")\n",
    "        f.write(\"\\\\end{table}\\n\")\n",
    "    \n",
    "    print(f\"LaTeX table exported to: {latex_file}\")\n",
    "    \n",
    "    # Generate methodology text for thesis\n",
    "    methodology_file = 'checkpoints/methodology_text.txt'\n",
    "    with open(methodology_file, 'w') as f:\n",
    "        f.write(\"METHODOLOGY TEXT FOR THESIS\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        f.write(\"Architecture-Specific Hyperparameter Optimization:\\n\\n\")\n",
    "        f.write(\"Following established practices in computer vision research (Xie et al., 2021; \")\n",
    "        f.write(\"Liu et al., 2021), each model was trained with architecture-specific hyperparameters \")\n",
    "        f.write(\"optimized for its design characteristics. Transformer-based models (SegFormer and \")\n",
    "        f.write(\"GhanaSegNet) employed a lower learning rate (5√ó10‚Åª‚Åµ) compared to CNN-based \")\n",
    "        f.write(\"architectures (UNet and DeepLabV3+: 1√ó10‚Åª‚Å¥) to accommodate the sensitivity of \")\n",
    "        f.write(\"self-attention mechanisms to large weight updates.\\n\\n\")\n",
    "        f.write(\"Additional optimizations for transformer-based models included:\\n\")\n",
    "        f.write(\"- Linear warmup schedule over 5 epochs for attention weight initialization\\n\")\n",
    "        f.write(\"- Stricter gradient clipping (max_norm=1.0 vs. 5.0 for CNNs)\\n\")\n",
    "        f.write(\"- ReduceLROnPlateau learning rate scheduler with patience=3\\n\")\n",
    "        f.write(\"- Early stopping with patience=20 epochs\\n\\n\")\n",
    "        f.write(\"This approach ensures each architecture achieves its optimal performance rather \")\n",
    "        f.write(\"than constraining all models to identical hyperparameters, which would be \")\n",
    "        f.write(\"inappropriate given their fundamental architectural differences.\\n\")\n",
    "    \n",
    "    print(f\"Methodology text exported to: {methodology_file}\")\n",
    "    \n",
    "    print(\"\\nExport complete. All results ready for thesis documentation.\")\n",
    "    print(\"\\nGenerated files:\")\n",
    "    print(f\"  - {output_file} (JSON format)\")\n",
    "    print(f\"  - {latex_file} (LaTeX table)\")\n",
    "    print(f\"  - {methodology_file} (Methodology text)\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Export error: {e}\")\n",
    "    print(\"Please ensure training has completed and results are available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7841c3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Training Complete!\n",
    "\n",
    "**Next Steps:**\n",
    "1. Review the results in Section 9\n",
    "2. Export thesis materials from Section 10\n",
    "3. Download checkpoints from `checkpoints/` directory\n",
    "4. Compare GhanaSegNet performance with baselines\n",
    "\n",
    "**Expected Results:**\n",
    "- GhanaSegNet: **0.28-0.30 mIoU** (Target for 30 epochs)\n",
    "- DeepLabV3+ Baseline: **0.2544 mIoU**\n",
    "- Improvement: **+3-6% mIoU**\n",
    "\n",
    "---\n",
    "\n",
    "**Questions or Issues?**\n",
    "Check the project documentation or review training logs above."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
